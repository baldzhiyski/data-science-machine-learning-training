{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning & Rules\n",
    "\n",
    "### Zweck\n",
    "\n",
    "Dieses Notebook bereinigt den exportierten Subgraphen (bis zu **300.000 Tracks**) und erzwingt einen **stabilen Data Contract**.\n",
    "Ziel ist eine **konsistente und ML-fähige Clean-Layer**, die reproduzierbar für alle weiteren Analysen und Modelle verwendet wird.\n",
    "\n",
    "---\n",
    "\n",
    "### Vorgehen\n",
    "\n",
    "* Vereinheitlichung von Datentypen und Strukturen\n",
    "* Regelbasierte Bereinigung (Wertebereiche, Konsistenz, Duplikate)\n",
    "* Integritäts- und Plausibilitätsprüfungen\n",
    "* Deterministische, reproduzierbare Transformationen\n",
    "\n",
    "---\n",
    "\n",
    "### Input\n",
    "\n",
    "* Exportierte CSVs aus dem Sampling/EDA (`interim/…`)\n",
    "\n",
    "### Output\n",
    "\n",
    "* Bereinigte CSVs (Inspektion)\n",
    "* Parquet-Dateien (Training)\n",
    "* JSON-Report mit angewandten Regeln und Statistiken\n",
    "\n",
    "---\n",
    "\n",
    "### Ergebnis\n",
    "\n",
    "Eine **validierte, konsistente und reproduzierbare Datenbasis** als Grundlage für Feature Engineering und Modellierung.\n"
   ],
   "id": "98a8d858ee79f6ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "55db29e3093df49a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:15.849886Z",
     "start_time": "2026-01-24T22:02:15.818707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils.cleaning.core import (\n",
    "    POLICY,\n",
    "    snake_case,\n",
    "    run_cleaning_pipeline,\n",
    "    id_set, enforce_optional_fk_as_na, clean_bridge_fks,\n",
    "    build_profiles, PROFILE_SPECS,\n",
    "    apply_rule_stages, run_quality_gates, save_clean_layer_parquet, compute_rowcount_delta, write_cleaning_report\n",
    ")\n",
    "from utils.config.settings import RANDOM_SEED\n",
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "pd.set_option(\"display.max_columns\", 250)\n",
    "pd.set_option(\"display.max_rows\", 40)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "import utils.core.paths as paths\n",
    "\n",
    "importlib.reload(paths)\n",
    "\n",
    "SAMPLE_NAME = paths.load_sample_name()\n",
    "PATHS = paths.make_paths(SAMPLE_NAME)\n",
    "paths.ensure_dirs(PATHS)\n"
   ],
   "id": "2e3176134ae85f58",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load CSV Exports\n",
    "\n",
    "In diesem Schritt werden die zuvor exportierten **CSV-Dateien** in den\n",
    "Speicher geladen.\n",
    "Die CSVs repräsentieren den **verbundenen Subgraphen** des aktuellen Samples\n",
    "und bilden die Rohbasis für alle nachfolgenden Cleaning- und Validierungsschritte.\n",
    "\n",
    "Beim Laden wird **noch keine inhaltliche Bereinigung** durchgeführt –\n",
    "Ziel ist ausschließlich das **strukturgetreue Einlesen** der Daten, sodass\n",
    "alle Transformationen explizit und nachvollziehbar in den folgenden Schritten\n",
    "erfolgen können."
   ],
   "id": "b688d7f79e78003c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:19.083842Z",
     "start_time": "2026-01-24T22:02:15.856389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EXPECTED_FILES = {\n",
    "    \"tracks\": \"tracks.csv\",\n",
    "    \"audio_features\": \"audio_features.csv\",\n",
    "    \"albums\": \"albums.csv\",\n",
    "    \"artists\": \"artists.csv\",\n",
    "    \"genres\": \"genres.csv\",\n",
    "    \"r_albums_tracks\": \"r_albums_tracks.csv\",\n",
    "    \"r_track_artist\": \"r_track_artist.csv\",\n",
    "    \"r_artist_genre\": \"r_artist_genre.csv\",\n",
    "    \"r_albums_artists\": \"r_albums_artists.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    df.columns = [snake_case(c) for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "raw: Dict[str, pd.DataFrame] = {}\n",
    "missing = []\n",
    "\n",
    "for table, fname in EXPECTED_FILES.items():\n",
    "    fp = PATHS.raw_dir / fname\n",
    "    if fp.exists():\n",
    "        raw[table] = load_csv(fp)\n",
    "    else:\n",
    "        missing.append(table)\n",
    "\n",
    "print(\" Loaded tables:\", list(raw.keys()))\n",
    "if missing:\n",
    "    print(\"Missing CSV exports:\", missing)\n",
    "\n",
    "{k: v.shape for k, v in raw.items()}"
   ],
   "id": "2c0b0f9031f9d812",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded tables: ['tracks', 'audio_features', 'albums', 'artists', 'genres', 'r_albums_tracks', 'r_track_artist', 'r_artist_genre', 'r_albums_artists']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tracks': (300000, 10),\n",
       " 'audio_features': (299954, 15),\n",
       " 'albums': (195938, 6),\n",
       " 'artists': (187440, 4),\n",
       " 'genres': (5455, 1),\n",
       " 'r_albums_tracks': (340898, 2),\n",
       " 'r_track_artist': (407296, 2),\n",
       " 'r_artist_genre': (194023, 2),\n",
       " 'r_albums_artists': (224955, 2)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Drop Useless / High-Missing Columns\n",
    "\n",
    "Spalten ohne oder mit kaum nutzbarer Information werden frühzeitig entfernt,\n",
    "um die **Datenstruktur zu vereinfachen** und **Rauschen** für nachgelagerte\n",
    "Analysen und Modelle zu reduzieren.\n",
    "\n",
    "Dabei gelten folgende Prinzipien:\n",
    "- Spalten mit **100 % Missing Values** enthalten keine Information → werden entfernt.\n",
    "- **High-Cardinality-Textfelder** (z. B. URLs) werden nicht direkt als Features genutzt.\n",
    "  Stattdessen werden – falls sinnvoll – **binäre Indikatoren** abgeleitet\n",
    "  (z. B. `has_preview`), um das enthaltene Signal zu erhalten.\n",
    "- Technische oder redundante Felder ohne analytischen Mehrwert werden entfernt.\n",
    "\n",
    "Dieses Vorgehen reduziert Speicherbedarf und Modellkomplexität, ohne relevante\n",
    "Information zu verlieren."
   ],
   "id": "4b72e739ba9a886d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:19.607402Z",
     "start_time": "2026-01-24T22:02:19.585301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if \"tracks\" in raw:\n",
    "    raw[\"tracks\"] = raw[\"tracks\"].drop(columns=[\"is_playable\"], errors=\"ignore\")\n",
    "\n",
    "if \"albums\" in raw:\n",
    "    raw[\"albums\"] = raw[\"albums\"].drop(columns=[\"album_group\"], errors=\"ignore\")\n",
    "\n",
    "if \"tracks\" in raw and \"preview_url\" in raw[\"tracks\"].columns:\n",
    "    raw[\"tracks\"][\"has_preview\"] = raw[\"tracks\"][\"preview_url\"].notna().astype(\"int8\")\n",
    "    raw[\"tracks\"] = raw[\"tracks\"].drop(columns=[\"preview_url\"], errors=\"ignore\")"
   ],
   "id": "a6fa3c60ca82f7d3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Applying the Cleaning\n",
    "\n",
    "Das Cleaning wird als **deterministische Pipeline** auf alle vorhandenen Tabellen\n",
    "angewendet.\n",
    "Jede Tabelle wird nur dann verarbeitet, wenn sie im aktuellen Sample existiert.\n",
    "\n",
    "Dabei werden:\n",
    "- tabellenspezifische **Cleaner** ausgeführt,\n",
    "- Regeln konsistent durchgesetzt,\n",
    "- und die Struktur der Daten vereinheitlicht.\n",
    "\n",
    "Das Ergebnis ist eine **vollständig bereinigte Clean-Layer**, die als Grundlage\n",
    "für Validierung, Reporting und nachfolgende Modellierungs-Schritte dient."
   ],
   "id": "eac88fafd74fd286"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:26.337919Z",
     "start_time": "2026-01-24T22:02:19.614414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned = run_cleaning_pipeline(raw)\n",
    "{k: v.shape for k, v in cleaned.items()}"
   ],
   "id": "a2b1922c65d18af3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tracks': (300000, 9),\n",
       " 'audio_features': (299954, 15),\n",
       " 'albums': (195938, 6),\n",
       " 'artists': (187440, 4),\n",
       " 'genres': (5455, 1),\n",
       " 'r_albums_tracks': (340898, 2),\n",
       " 'r_track_artist': (407296, 2),\n",
       " 'r_artist_genre': (194023, 2),\n",
       " 'r_albums_artists': (224955, 2)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Referential Integrity Enforcement\n",
    "\n",
    "Nach dem tabellenspezifischen Cleaning wird die **referenzielle Integrität** zwischen\n",
    "Entitäten und Bridge-Tabellen erzwungen, um eine **konsistente Graph-/Join-Struktur**\n",
    "sicherzustellen.\n",
    "\n",
    "### Bridge-Tabellen (Orphan-Removal)\n",
    "Für alle Many-to-Many-Beziehungen werden **verwaiste Relationen (Orphans)** entfernt:\n",
    "- Eine Zeile in einer Bridge-Tabelle bleibt nur erhalten, wenn **alle referenzierten IDs**\n",
    "  in den jeweiligen Entity-Tabellen existieren (z. B. `track_id ∈ tracks`, `artist_id ∈ artists`).\n",
    "\n",
    "Dadurch wird verhindert, dass spätere Joins:\n",
    "- Datensätze künstlich aufblasen,\n",
    "- fehlerhafte Verknüpfungen erzeugen,\n",
    "- oder Modell-/EDA-Ergebnisse verfälschen.\n",
    "\n",
    "### Optionale Foreign Keys (Soft Enforcement)\n",
    "Einige Referenzen werden als **optional** behandelt (z. B. `tracks.audio_feature_id`):\n",
    "- Ungültige Referenzen werden **nicht** durch Dropping der Track-Zeile behandelt,\n",
    "  sondern auf `NaN` gesetzt.\n",
    "- So bleibt der Track als Beobachtung erhalten, auch wenn die Zusatzinformationen fehlen.\n",
    "\n",
    "**Ergebnis:**\n",
    "Eine Clean-Layer mit **konsistenten Beziehungen**, ohne unnötigen Informationsverlust\n",
    "durch aggressives Entfernen von Entitätszeilen."
   ],
   "id": "b8c3148e6d0e3959"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:28.917926Z",
     "start_time": "2026-01-24T22:02:26.809614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- ID Sets (aus Clean-Layer) ---\n",
    "track_ids = id_set(cleaned, \"tracks\", \"track_id\")\n",
    "album_ids = id_set(cleaned, \"albums\", \"id\")\n",
    "artist_ids = id_set(cleaned, \"artists\", \"id\")\n",
    "genre_ids = id_set(cleaned, \"genres\", \"id\")\n",
    "af_ids = id_set(cleaned, \"audio_features\", \"id\")\n",
    "\n",
    "# --- Bridge-FK Specs ---\n",
    "bridge_fk_specs = {\n",
    "    \"r_albums_tracks\": ((\"album_id\", album_ids), (\"track_id\", track_ids)),\n",
    "    \"r_track_artist\": ((\"track_id\", track_ids), (\"artist_id\", artist_ids)),\n",
    "    \"r_artist_genre\": ((\"genre_id\", genre_ids), (\"artist_id\", artist_ids)),\n",
    "    \"r_albums_artists\": ((\"album_id\", album_ids), (\"artist_id\", artist_ids)),\n",
    "}\n",
    "\n",
    "# --- Anwenden ---\n",
    "if POLICY.drop_orphan_bridge_rows:\n",
    "    cleaned = clean_bridge_fks(cleaned, bridge_fk_specs)\n",
    "\n",
    "# Track -> audio_feature_id: invalid zu NA (nicht droppen)\n",
    "cleaned = enforce_optional_fk_as_na(cleaned, \"tracks\", \"audio_feature_id\", af_ids)\n",
    "\n",
    "{k: v.shape for k, v in cleaned.items()}"
   ],
   "id": "fc15949062984921",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tracks': (300000, 9),\n",
       " 'audio_features': (299954, 15),\n",
       " 'albums': (195938, 6),\n",
       " 'artists': (187440, 4),\n",
       " 'genres': (5455, 1),\n",
       " 'r_albums_tracks': (340898, 2),\n",
       " 'r_track_artist': (407296, 2),\n",
       " 'r_artist_genre': (194023, 2),\n",
       " 'r_albums_artists': (218032, 2)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Post-Cleaning Vergleich (Before vs. After)\n",
    "\n",
    "Die folgende Tabelle vergleicht zentrale Kennzahlen vor und nach dem Cleaning\n",
    "und zeigt die Netto-Auswirkungen (ΔRows, ΔMemory, ΔDuplikate) pro Tabelle."
   ],
   "id": "13a8fe12bcebad24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:29.884688Z",
     "start_time": "2026-01-24T22:02:29.570630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "profiles_before = build_profiles(raw, PROFILE_SPECS)\n",
    "profiles_after = build_profiles(cleaned, PROFILE_SPECS)\n",
    "\n",
    "df_before = pd.DataFrame.from_dict(profiles_before, orient=\"index\")\n",
    "df_after = pd.DataFrame.from_dict(profiles_after, orient=\"index\")\n",
    "\n",
    "compare = df_after[[\"rows\", \"memory_mb\", \"duplicate_rows_on_keys\"]].join(\n",
    "    df_before[[\"rows\", \"memory_mb\", \"duplicate_rows_on_keys\"]],\n",
    "    lsuffix=\"_after\", rsuffix=\"_before\"\n",
    ")\n",
    "\n",
    "compare[\"rows_delta\"] = compare[\"rows_after\"] - compare[\"rows_before\"]\n",
    "compare[\"mem_delta_mb\"] = compare[\"memory_mb_after\"] - compare[\"memory_mb_before\"]\n",
    "compare[\"dup_delta\"] = compare[\"duplicate_rows_on_keys_after\"] - compare[\"duplicate_rows_on_keys_before\"]\n",
    "\n",
    "compare[[\"rows_before\", \"rows_after\", \"rows_delta\", \"mem_delta_mb\", \"dup_delta\"]].sort_values(\"rows_delta\")\n"
   ],
   "id": "dfdb828144d91e3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  rows_before  rows_after  rows_delta  mem_delta_mb  dup_delta\n",
       "r_albums_artists       224955      218032       -6923         -0.93          0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows_before</th>\n",
       "      <th>rows_after</th>\n",
       "      <th>rows_delta</th>\n",
       "      <th>mem_delta_mb</th>\n",
       "      <th>dup_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r_albums_artists</th>\n",
       "      <td>224955</td>\n",
       "      <td>218032</td>\n",
       "      <td>-6923</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Outlier & rule-based validation + flags\n",
    "\n",
    "In diesem Schritt werden **Outlier nicht pauschal gelöscht** (z. B. via IQR), weil viele Spotify-Features **diskret**, **zero-inflated** oder **heavy-tail** verteilt sind. Ein IQR-Dropping wäre hier oft **zu aggressiv** und würde **gültige Spezialfälle** (z. B. Multi-Disc, Live-Tracks, sehr schnelle/langsame Songs) entfernen.\n",
    "\n",
    "Stattdessen nutzen wir ein **rule-based (Data-Contract) Vorgehen**:\n",
    "\n",
    "- **Domain-Verletzungen** (unmögliche Werte) → auf `NaN` setzen oder auf gültige Bereiche clippen\n",
    "- **Extreme, aber plausible Werte** (Long-Tail) → **Quantile-Capping** (Upper Tail), kein Dropping\n",
    "- **Signal erhalten** → zusätzliche **Flag-Features** (`is_*`) für Extremfälle\n",
    "\n",
    "### Policy (konkret)\n",
    "**Tracks**\n",
    "- `popularity`: Clip auf **[0, 100]**\n",
    "- `duration`: `<= 0` → `NaN`, **Upper-Tail Quantile-Cap** (z. B. 99.9%); Flag `is_long_track`\n",
    "- `track_number`: `<= 0` oder `> 200` → `NaN`; Flag `is_tracknum_extreme`\n",
    "- `disc_number`: `<= 0` → `NaN`; Flag `is_multidisc` (`> 1`); `> 10` → `NaN`; Flag `is_disc_extreme`\n",
    "\n",
    "**Audio Features**\n",
    "- `time_signature`: nur `{3,4,5}` gültig → sonst `NaN`; Flag `is_time_signature_rare`\n",
    "- `tempo`: `<= 0` → `NaN`, **Upper-Tail Quantile-Cap** (z. B. 99.9%); Flag `is_tempo_extreme`\n",
    "- `loudness`: außerhalb **[-60, 5]** → `NaN`; Flag `is_loudness_very_low` (`< -40`)\n",
    "- `speechiness`: Clip auf **[0, 1]**; Flag `is_high_speech` (≥ 90%-Quantil)\n",
    "- `instrumentalness`: Clip auf **[0, 1]**; Flag `is_instrumental` (≥ 0.5)\n",
    "- `key`: nur **0–11** gültig → sonst `NaN`\n",
    "- `mode`: nur **0–1** gültig → sonst `NaN`\n",
    "\n",
    "**Artists**\n",
    "- `followers`: `< 0` → `NaN`, **Upper-Tail Quantile-Cap** (z. B. 99.9%); Flag `is_followers_extreme`\n",
    "- Zusatzfeature: `followers_log1p = log1p(followers)`\n",
    "- `popularity`: Clip auf **[0, 100]**\n",
    "\n",
    "**Albums**\n",
    "- `release_date_parsed`: Jahr nur im Bereich **1900–2035** gültig → sonst `NaT`; Flag `is_release_year_invalid`\n",
    "- `popularity`: Clip auf **[0, 100]**\n",
    "\n",
    "So bleibt die Datenbasis **stabil und konsistent** für ML, ohne durch aggressives Dropping die Graph-/Join-Struktur oder seltene, aber valide Fälle zu verlieren."
   ],
   "id": "4d1b5e60666a2f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:30.839098Z",
     "start_time": "2026-01-24T22:02:30.608104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned = apply_rule_stages(cleaned)\n",
    "print(\"Outlier rules applied: rule-based invalidation + quantile caps + flags (no IQR dropping).\")\n"
   ],
   "id": "75945b45f48460f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier rules applied: rule-based invalidation + quantile caps + flags (no IQR dropping).\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quality Gates (Data Contract Enforcement)\n",
    "\n",
    "Nach Abschluss des Cleanings werden **Quality Gates** ausgeführt, um sicherzustellen,\n",
    "dass der definierte **Data Contract** eingehalten wird.\n",
    "Diese Gates dienen **nicht** der weiteren Bereinigung, sondern der **Validierung**\n",
    "der finalen Clean-Layer.\n",
    "\n",
    "### Geprüfte Invarianten\n",
    "\n",
    "**Primärschlüssel (PK)**\n",
    "- Alle PKs sind **nicht-null** und **eindeutig**\n",
    "  - `tracks.track_id`\n",
    "  - `audio_features.id`\n",
    "  - `albums.id`\n",
    "  - `artists.id`\n",
    "  - `genres.id`\n",
    "\n",
    "**Wertebereiche / Domänen**\n",
    "- `popularity` ∈ **[0, 100]**\n",
    "- `tracks.duration` > **0**\n",
    "- Audio-Features im Bereich **[0, 1]** (`acousticness`, `energy`, …)\n",
    "\n",
    "**Referenzielle Integrität (Bridges)**\n",
    "- Alle Bridge-Tabellen enthalten **keine Orphan-Relations**\n",
    "  - z. B. `album_id` ∈ `albums.id`, `track_id` ∈ `tracks.track_id`\n",
    "\n",
    "### Verhalten bei Verstößen\n",
    "Ein Verstoß gegen ein Quality Gate führt zu einem **harten Abbruch** des Notebooks.\n",
    "Dadurch wird sichergestellt, dass **keine inkonsistenten Daten** in nachgelagerte\n",
    "Schritte (Feature Engineering, Modelltraining) gelangen.\n",
    "\n",
    "### Zweck\n",
    "Quality Gates machen Annahmen über die Daten **explizit und überprüfbar** und\n",
    "fungieren als **formale Schnittstelle** zwischen Cleaning und Modellierung."
   ],
   "id": "d621e738ad2aa172"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:32.318198Z",
     "start_time": "2026-01-24T22:02:30.846107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id_sets = {\n",
    "    \"tracks\": set(cleaned[\"tracks\"][\"track_id\"].dropna().unique()) if \"tracks\" in cleaned else set(),\n",
    "    \"albums\": set(cleaned[\"albums\"][\"id\"].dropna().unique()) if \"albums\" in cleaned else set(),\n",
    "    \"artists\": set(cleaned[\"artists\"][\"id\"].dropna().unique()) if \"artists\" in cleaned else set(),\n",
    "    \"genres\": set(cleaned[\"genres\"][\"id\"].dropna().unique()) if \"genres\" in cleaned else set(),\n",
    "}\n",
    "\n",
    "run_quality_gates(cleaned, id_sets=id_sets)\n",
    "print(\"All quality gates passed.\")"
   ],
   "id": "c9596ac9e1d556c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All quality gates passed.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saving & Cleaning Report (JSON) — Audit & Reproducibility\n",
    "\n",
    "Nach Abschluss des Cleanings wird ein **strukturierter Cleaning-Report** als JSON\n",
    "gespeichert. Dieser Report dient der **Auditierbarkeit**, **Nachvollziehbarkeit**\n",
    "und **Reproduzierbarkeit** der gesamten Cleaning-Pipeline.\n",
    "\n",
    "### Enthaltene Informationen\n",
    "- **Profiles (Before / After)**\n",
    "  Tabellenstatistiken vor und nach dem Cleaning (Rows, Columns, Memory, Duplikate)\n",
    "\n",
    "- **Rowcount Delta**\n",
    "  Zeigt explizit, wie sich die Anzahl der Zeilen pro Tabelle durch das Cleaning\n",
    "  verändert hat (z. B. durch Entfernen von Duplikaten oder Orphan-Relations)\n",
    "\n",
    "- **Cleaning Notes / Policies**\n",
    "  Dokumentiert zentrale Entscheidungen (z. B. FK-Policy, Popularity-Clipping,\n",
    "  Duplikat-Strategie)\n",
    "\n",
    "- **Run Metadata**\n",
    "  Laufzeitinformationen (Timestamp, Environment, Policy, Pfade) zur vollständigen\n",
    "  Reproduzierbarkeit\n",
    "\n",
    "### Zweck\n",
    "Der Cleaning-Report stellt sicher, dass jede erzeugte Clean-Layer **versionierbar,\n",
    "prüfbar und reproduzierbar** ist und bildet die formale Schnittstelle zwischen\n",
    "Data Cleaning und nachgelagerten Analyse- bzw. Modellierungs-Schritten."
   ],
   "id": "2c50c595ec23259"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T22:02:34.675836Z",
     "start_time": "2026-01-24T22:02:32.802503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean Layer als Parquet speichern\n",
    "save_clean_layer_parquet(cleaned, PATHS.clean_parquet_dir)\n",
    "print(\"Clean layer saved to:\", PATHS.clean_parquet_dir)\n",
    "\n",
    "\n",
    "# Delta berechnen\n",
    "rowcount_delta = compute_rowcount_delta(raw, cleaned)\n",
    "\n",
    "# Notes (kurz halten)\n",
    "notes = {\n",
    "\"bridge_policy\": \"drop orphan rows (referential integrity enforced)\",\n",
    "\"track_audio_feature_fk_policy\": \"invalid audio_feature_id set to NA (tracks not dropped)\",\n",
    "\"popularity_policy\": \"clipped to [0,100]\",\n",
    "\"duplicate_policy\": \"kept the most complete row per PK\",\n",
    "\"export_formats\": \"Parquet\",\n",
    "}\n",
    "\n",
    "\n",
    "# Report schreiben\n",
    "report_path = PATHS.reports_dir_cleaning / \"cleaning_report.json\"\n",
    "write_cleaning_report(\n",
    "report_path=report_path,\n",
    "profiles_before=profiles_before,\n",
    "profiles_after=profiles_after,\n",
    "rowcount_delta=rowcount_delta,\n",
    "notes=notes\n",
    ")\n",
    "print(\"Cleaning report written:\", report_path)"
   ],
   "id": "6494a48ef8cab8fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean layer saved to: C:\\GitHub\\uni-project-metrics-and-data\\data\\processed\\parquet\\slice_001\n",
      "Cleaning report written: C:\\GitHub\\uni-project-metrics-and-data\\data\\reports\\cleaning\\slice_001\\cleaning_report.json\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
