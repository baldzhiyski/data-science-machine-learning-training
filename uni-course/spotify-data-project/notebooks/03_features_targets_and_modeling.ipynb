{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:39:13.251617Z",
     "start_time": "2025-12-23T09:39:13.243978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import json\n",
    "import time\n",
    "import platform\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    roc_auc_score, average_precision_score, f1_score,confusion_matrix\n",
    ")\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "from joblib import dump"
   ],
   "id": "c8a583208350f2c1",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Global Config",
   "id": "af6c0da03f435c6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 03 — Targets, Features & Modeling (scikit-learn Pipelines + XGBoost)\n",
    "\n",
    "## Ziel\n",
    "Dieses Notebook erstellt **saubere ML-Datensätze** (Features + Targets) und trainiert mehrere Modelle als **reproduzierbare Pipelines**.\n",
    "\n",
    "Am Ende erzeugen wir:\n",
    "- vorbereitete Feature-Matrizen\n",
    "- gespeicherte Modell-Pipelines (`.joblib`)\n",
    "- strukturierte Reports (`metrics_report.json`, `feature_config.json`)\n",
    "\n"
   ],
   "id": "b08a44e3b365e59f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:39:13.270999Z",
     "start_time": "2025-12-23T09:39:13.265438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Leakage controls:\n",
    "# - If True: allow \"post-release / popularity-like\" proxy features\n",
    "# - If False: drop strongest leakage/proxies\n",
    "ALLOW_LEAKY_FEATURES = False\n",
    "\n",
    "# \"Main album per track\" selection strategy:\n",
    "# - \"earliest_release\": choose album with earliest release_date_parsed\n",
    "# - \"deterministic_id\": choose smallest album_id (stable fallback)\n",
    "MAIN_ALBUM_STRATEGY = \"earliest_release\"\n",
    "\n",
    "# Hit label definition\n",
    "HIT_PERCENTILE = 0.80\n",
    "HIT_FALLBACK_POP_THRESHOLD = 60\n",
    "\n",
    "# Genre multi-hot size\n",
    "TOP_K_GENRES = 50\n",
    "\n",
    "# Mood labels quantile rules (weak-label demonstration)\n",
    "MOOD_TAGS = [\n",
    "    (\"energetic\", \"energy\", 0.75, \"gt\"),\n",
    "    (\"danceable\", \"danceability\", 0.75, \"gt\"),\n",
    "    (\"acoustic\", \"acousticness\", 0.75, \"gt\"),\n",
    "    (\"instrumental\", \"instrumentalness\", 0.75, \"gt\"),\n",
    "    (\"happy\", \"valence\", 0.75, \"gt\"),\n",
    "    (\"sad\", \"valence\", 0.25, \"lt\"),\n",
    "    (\"chill\", \"energy\", 0.25, \"lt\"),\n",
    "]\n",
    "\n",
    "# Clustering\n",
    "K_CLUSTERS = 30\n",
    "TSNE_SAMPLE_MAX = 4000\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 250)\n",
    "pd.set_option(\"display.width\", 180)\n",
    "pd.set_option(\"display.max_rows\", 40)\n",
    "try:\n",
    "    pd.options.mode.copy_on_write = True\n",
    "except Exception:\n",
    "    pass"
   ],
   "id": "6dc5ad4ecdd03c74",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paths",
   "id": "b6bb50c3a614111d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:39:13.287019Z",
     "start_time": "2025-12-23T09:39:13.279382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    clean_parquet_dir: Path = Path(\"../data/processed/parquet\")\n",
    "    clean_csv_dir: Path = Path(\"../data/processed/clean_csv\")\n",
    "\n",
    "    modeling_dir: Path = Path(\"../data/processed/modeling\")\n",
    "    models_dir: Path = Path(\"../data/models\")\n",
    "    reports_dir: Path = Path(\"../data/reports/03_target_and_features\")\n",
    "\n",
    "PATHS = Paths()\n",
    "for p in [PATHS.modeling_dir, PATHS.models_dir, PATHS.reports_dir]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RUN_META = {\n",
    "    \"run_ts_unix\": int(time.time()),\n",
    "    \"python\": platform.python_version(),\n",
    "    \"platform\": platform.platform(),\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"allow_leaky_features\": ALLOW_LEAKY_FEATURES,\n",
    "    \"main_album_strategy\": MAIN_ALBUM_STRATEGY,\n",
    "    \"paths\": {k: str(v) for k, v in asdict(PATHS).items()},\n",
    "}"
   ],
   "id": "c9edd2734a912c84",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loading",
   "id": "f5740e6b93204582"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:39:13.831714Z",
     "start_time": "2025-12-23T09:39:13.295715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TABLES = [\n",
    "    \"tracks\",\n",
    "    \"audio_features\",\n",
    "    \"albums\",\n",
    "    \"artists\",\n",
    "    \"genres\",\n",
    "    \"r_albums_tracks\",\n",
    "    \"r_track_artist\",\n",
    "    \"r_artist_genre\",\n",
    "    \"r_albums_artists\",\n",
    "]\n",
    "\n",
    "def load_table(name: str) -> pd.DataFrame:\n",
    "    pq = PATHS.clean_parquet_dir / f\"{name}.parquet\"\n",
    "    csv = PATHS.clean_csv_dir / f\"{name}.csv\"\n",
    "\n",
    "    if pq.exists():\n",
    "        return pd.read_parquet(pq)\n",
    "    if csv.exists():\n",
    "        return pd.read_csv(csv, low_memory=False)\n",
    "    raise FileNotFoundError(f\"Missing {name} in parquet/csv clean layer.\")\n",
    "\n",
    "data: Dict[str, pd.DataFrame] = {}\n",
    "for t in TABLES:\n",
    "    pq = PATHS.clean_parquet_dir / f\"{t}.parquet\"\n",
    "    csv = PATHS.clean_csv_dir / f\"{t}.csv\"\n",
    "    if pq.exists() or csv.exists():\n",
    "        data[t] = load_table(t)\n",
    "\n",
    "{k: v.shape for k, v in data.items()}"
   ],
   "id": "d9405634cbfbecdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tracks': (294618, 13),\n",
       " 'audio_features': (294594, 21),\n",
       " 'albums': (129152, 8),\n",
       " 'artists': (139608, 6),\n",
       " 'genres': (5416, 1),\n",
       " 'r_albums_tracks': (305933, 2),\n",
       " 'r_track_artist': (391700, 2),\n",
       " 'r_artist_genre': (169289, 2),\n",
       " 'r_albums_artists': (142153, 2)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Quick integrity sanity",
   "id": "a4817b7804f2c03b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:39:14.027262Z",
     "start_time": "2025-12-23T09:39:13.850243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "required = [\"tracks\", \"audio_features\", \"albums\", \"artists\", \"r_albums_tracks\", \"r_track_artist\", \"r_artist_genre\"]\n",
    "missing = [t for t in required if t not in data]\n",
    "assert not missing, f\"Missing required tables in clean layer: {missing}\"\n",
    "\n",
    "tracks = data[\"tracks\"].copy()\n",
    "audio = data[\"audio_features\"].copy()\n",
    "albums = data[\"albums\"].copy()\n",
    "artists = data[\"artists\"].copy()\n",
    "rat = data[\"r_albums_tracks\"].copy()\n",
    "rta = data[\"r_track_artist\"].copy()\n",
    "rag = data[\"r_artist_genre\"].copy()\n",
    "genres = data.get(\"genres\", pd.DataFrame(columns=[\"id\"]))  # optional\n",
    "raa = data.get(\"r_albums_artists\", pd.DataFrame(columns=[\"album_id\", \"artist_id\"])).copy()\n",
    "\n",
    "# PK expectations (guarded)\n",
    "assert \"track_id\" in tracks.columns, \"tracks must contain track_id\"\n",
    "assert tracks[\"track_id\"].is_unique\n",
    "\n",
    "assert \"id\" in audio.columns and audio[\"id\"].is_unique\n",
    "assert \"id\" in albums.columns and albums[\"id\"].is_unique\n",
    "assert \"id\" in artists.columns and artists[\"id\"].is_unique\n",
    "\n",
    "if not genres.empty and \"id\" in genres.columns:\n",
    "    assert genres[\"id\"].is_unique\n",
    "\n",
    "print(\"Clean layer looks consistent.\")"
   ],
   "id": "9a9f17ba7d8cecb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean layer looks consistent.\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper utilities",
   "id": "1a46c34d0eabf306"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:39:14.059389Z",
     "start_time": "2025-12-23T09:39:14.045063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def col_or_na(df: pd.DataFrame, col: str, dtype: Optional[str] = None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return df[col] if it exists; otherwise return an all-NA Series with the same index.\n",
    "    Never returns None.\n",
    "    \"\"\"\n",
    "    if df is None or not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"col_or_na: df must be a pandas DataFrame\")\n",
    "\n",
    "    if col in df.columns:\n",
    "        s = df[col]\n",
    "        if dtype is not None:\n",
    "            try:\n",
    "                s = s.astype(dtype)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s\n",
    "\n",
    "    return pd.Series(pd.NA, index=df.index)\n",
    "\n",
    "def safe_len_series(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(\"string\").fillna(\"\").str.len().astype(\"int32\")\n",
    "\n",
    "def safe_word_count_series(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(\"string\").fillna(\"\").str.split().str.len().astype(\"int32\")\n",
    "\n",
    "def add_release_time_features(df: pd.DataFrame, date_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Adds release_year/month/decade from a datetime-like column.\"\"\"\n",
    "    df = df.copy()\n",
    "    dt = pd.to_datetime(col_or_na(df, date_col), errors=\"coerce\")\n",
    "    df[\"release_year\"] = dt.dt.year.astype(\"Int64\")\n",
    "    df[\"release_month\"] = dt.dt.month.astype(\"Int64\")\n",
    "    df[\"release_decade\"] = ((dt.dt.year // 10) * 10).astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def log1p_numeric(s: pd.Series) -> pd.Series:\n",
    "    x = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return np.log1p(x).astype(\"float64\")\n",
    "\n",
    "def ensure_list_column(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ensure a column contains python lists.\n",
    "    Accepts:\n",
    "      - actual lists\n",
    "      - JSON strings\n",
    "      - repr strings like \"['a','b']\"\n",
    "      - NaN/None\n",
    "    \"\"\"\n",
    "    def parse_one(v):\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "        if v is None or (isinstance(v, float) and np.isnan(v)):\n",
    "            return []\n",
    "        if isinstance(v, str):\n",
    "            v = v.strip()\n",
    "            if not v:\n",
    "                return []\n",
    "            # try JSON\n",
    "            try:\n",
    "                parsed = json.loads(v)\n",
    "                if isinstance(parsed, list):\n",
    "                    return parsed\n",
    "            except Exception:\n",
    "                pass\n",
    "            # try python literal\n",
    "            try:\n",
    "                parsed = ast.literal_eval(v)\n",
    "                if isinstance(parsed, list):\n",
    "                    return parsed\n",
    "            except Exception:\n",
    "                pass\n",
    "        return []\n",
    "    return s.apply(parse_one)\n",
    "\n",
    "def top_k_list_counts(list_series: pd.Series, top_k: int) -> List[str]:\n",
    "    from collections import Counter\n",
    "    c = Counter()\n",
    "    for lst in list_series:\n",
    "        if isinstance(lst, list):\n",
    "            for x in lst:\n",
    "                if pd.notna(x):\n",
    "                    c[str(x)] += 1\n",
    "    return [k for k, _ in c.most_common(top_k)]\n",
    "\n",
    "def genres_to_multihot(df: pd.DataFrame, list_col: str, top_genres: List[str], prefix: str) -> pd.DataFrame:\n",
    "    if not top_genres:\n",
    "        return pd.DataFrame(index=df.index)\n",
    "    m = np.zeros((len(df), len(top_genres)), dtype=np.int8)\n",
    "    idx = {g: i for i, g in enumerate(top_genres)}\n",
    "    lists = df[list_col]\n",
    "    for r, lst in enumerate(lists):\n",
    "        if isinstance(lst, list):\n",
    "            for g in lst:\n",
    "                j = idx.get(str(g))\n",
    "                if j is not None:\n",
    "                    m[r, j] = 1\n",
    "    return pd.DataFrame(m, columns=[f\"{prefix}genre_{g}\" for g in top_genres])\n",
    "\n",
    "def onehot_encoder_compat() -> OneHotEncoder:\n",
    "    \"\"\"Handle sklearn versions where sparse_output may not exist.\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "def kmeans_compat(n_clusters: int, random_state: int) -> KMeans:\n",
    "    \"\"\"Handle sklearn versions where n_init='auto' may not exist.\"\"\"\n",
    "    try:\n",
    "        return KMeans(n_clusters=n_clusters, n_init=\"auto\", random_state=random_state)\n",
    "    except TypeError:\n",
    "        return KMeans(n_clusters=n_clusters, n_init=10, random_state=random_state)\n",
    "\n",
    "def regression_report(y_true, y_pred) -> Dict[str, float]:\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    return {\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": float(r2_score(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "def classification_report_binary(y_true, y_proba, threshold=0.5) -> Dict[str, Any]:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_proba = np.asarray(y_proba)\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    out = {\n",
    "        \"roc_auc\": float(roc_auc_score(y_true, y_proba)) if len(np.unique(y_true)) > 1 else None,\n",
    "        \"pr_auc\": float(average_precision_score(y_true, y_proba)) if len(np.unique(y_true)) > 1 else None,\n",
    "        \"f1\": float(f1_score(y_true, y_pred)) if len(np.unique(y_true)) > 1 else None,\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist(),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def best_f1_threshold(y_true, proba, thresholds=np.linspace(0.05, 0.95, 19)):\n",
    "    best_t, best_f1 = 0.5, -1\n",
    "    for t in thresholds:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        f1 = f1_score(y_true, pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    return float(best_t), float(best_f1)\n"
   ],
   "id": "50becf1736ac7860",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Track-Level Dataset (eine Zeile = ein Track)\n",
    "\n",
    "**Ziel:** Wir bauen eine denormalisierte, ML-fertige Tabelle, in der **jede Zeile einen Track** repräsentiert.\n",
    "Dazu kombinieren wir Informationen aus mehreren Tabellen (Tracks, Audio-Features, Alben, Artists, Genres) und erzeugen zusätzlich **aggregierte** sowie **engineerte Features**.\n",
    "\n",
    "### Was passiert hier genau?\n",
    "\n",
    "1. **Tracks + Audio-Features (1:1 / left join)**\n",
    "   - Wir hängen die numerischen Audio-Features (z. B. energy, danceability, loudness, tempo) direkt an den Track.\n",
    "   - Falls für einzelne Tracks keine Audio-Features existieren, bleiben diese Felder `NaN` (left join).\n",
    "\n",
    "2. **Track → Album (Many-to-Many) und Auswahl eines „Main Albums“**\n",
    "   - Ein Track kann auf mehreren Alben vorkommen (Album, Compilation, Re-Release).\n",
    "   - Für ML brauchen wir aber **einen eindeutigen Album-Kontext** pro Track.\n",
    "   - Deshalb wählen wir deterministisch genau **ein Album pro Track** (z. B. das früheste Release-Datum).\n",
    "\n",
    "3. **Album-Metadaten an Track anhängen**\n",
    "   - Wir mergen Album-Infos (z. B. album_type, release_date, album_popularity) auf Track-Ebene.\n",
    "   - Danach erzeugen wir Zeitfeatures wie `release_year`, `release_month`, `release_decade`.\n",
    "\n",
    "4. **Track → Artists (Many-to-Many) + Aggregation**\n",
    "   - Ein Track kann mehrere Artists haben (feat., collabs).\n",
    "   - Wir speichern:\n",
    "     - `artist_ids` als Liste (für spätere Analysen)\n",
    "     - Aggregierte Artist-Statistiken pro Track:\n",
    "       - Anzahl Artists (`n_artists`)\n",
    "       - Mittelwert/Maximum von Artist-Popularität und Followers\n",
    "\n",
    "5. **Track → Genres über Artist-Genres (Many-to-Many, Union)**\n",
    "   - Genres hängen bei Spotify oft an Artists, nicht direkt an Tracks.\n",
    "   - Wir bauen:\n",
    "     - `artist_id -> [genre_ids]`\n",
    "     - `track_id -> union(artist_genres)` als `track_genres` (Liste)\n",
    "\n",
    "6. **Feature Engineering**\n",
    "   - Aus Text / Metadaten:\n",
    "     - `has_preview`: ob Preview-URL vorhanden ist (0/1)\n",
    "     - `name_len`, `name_words`: Länge und Wortanzahl des Track-Namens\n",
    "   - Log-Transforms:\n",
    "     - `log_duration`: reduziert Schiefe bei Dauer\n",
    "     - `log_artist_followers_*`: stabilisiert heavy-tailed follower counts\n",
    "   - Qualitätsindikatoren:\n",
    "     - `has_audio_features`: ob Audio-Features vorhanden sind (0/1)\n",
    "\n",
    "**Ergebnis:** `track_df` ist eine „Feature-Matrix“ auf Track-Ebene"
   ],
   "id": "4779449637d47f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:40:12.943757Z",
     "start_time": "2025-12-23T09:39:14.066796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) Join: tracks -> audio_features (left join)\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Audio features are core ML predictors (danceability, energy, loudness, tempo, ...)\n",
    "#   - Left join keeps all tracks even if audio features are missing for some rows.\n",
    "assert \"audio_feature_id\" in tracks.columns, \"tracks must contain audio_feature_id for join with audio_features.id\"\n",
    "\n",
    "# Rename audio PK 'id' to match tracks FK 'audio_feature_id'\n",
    "audio_small = audio.rename(columns={\"id\": \"audio_feature_id\"})\n",
    "\n",
    "# Merge track metadata + audio features into one wide table\n",
    "track_df = tracks.merge(audio_small, on=\"audio_feature_id\", how=\"left\", suffixes=(\"\", \"_af\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Track -> Album (Many-to-Many) and choose ONE \"main album\"\n",
    "# ------------------------------------------------------------\n",
    "# Problem:\n",
    "#   - A track can appear on multiple albums (releases, compilations, deluxe editions).\n",
    "# ML requirement:\n",
    "#   - We want a single album context per track to avoid duplicate rows / ambiguity.\n",
    "# Strategy:\n",
    "#   - Deterministic selection:\n",
    "#       MAIN_ALBUM_STRATEGY == \"earliest_release\" -> pick earliest release_date\n",
    "#       else -> pick smallest album_id (stable fallback)\n",
    "albums_for_pick = albums.copy().rename(columns={\"id\": \"album_id\"})\n",
    "albums_for_pick[\"release_date_parsed\"] = pd.to_datetime(\n",
    "    col_or_na(albums_for_pick, \"release_date_parsed\"), errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Attach album release dates to the relationship table (album_id, track_id)\n",
    "rat2 = rat.merge(\n",
    "    albums_for_pick[[\"album_id\", \"release_date_parsed\"]],\n",
    "    on=\"album_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Pick main album per track based on strategy\n",
    "if MAIN_ALBUM_STRATEGY == \"earliest_release\":\n",
    "    rat2 = rat2.sort_values([\"track_id\", \"release_date_parsed\", \"album_id\"], ascending=[True, True, True])\n",
    "    main_album_per_track = rat2.drop_duplicates(\"track_id\", keep=\"first\")[[\"track_id\", \"album_id\"]]\n",
    "else:\n",
    "    rat2 = rat2.sort_values([\"track_id\", \"album_id\"], ascending=[True, True])\n",
    "    main_album_per_track = rat2.drop_duplicates(\"track_id\", keep=\"first\")[[\"track_id\", \"album_id\"]]\n",
    "\n",
    "# Merge the selected main album_id into track_df\n",
    "track_df = track_df.merge(main_album_per_track, on=\"track_id\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Merge album metadata onto track\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - album_type / release_date provide useful context\n",
    "#   - album_popularity is a strong proxy but can be leakage depending on your goal\n",
    "#     (you can later drop it via ALLOW_LEAKY_FEATURES switch in feature selection)\n",
    "albums_join = albums_for_pick.copy()\n",
    "\n",
    "# Rename to avoid name clash with track popularity\n",
    "rename_map = {}\n",
    "if \"popularity\" in albums_join.columns:\n",
    "    rename_map[\"popularity\"] = \"album_popularity\"\n",
    "albums_join = albums_join.rename(columns=rename_map)\n",
    "\n",
    "track_df = track_df.merge(albums_join, on=\"album_id\", how=\"left\", suffixes=(\"\", \"_album\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Add release time features (year/month/decade)\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Popularity and audio trends are time-dependent\n",
    "#   - Helps model capture temporal shift and era effects\n",
    "track_df = add_release_time_features(track_df, \"release_date_parsed\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Track -> Artists list (Many-to-Many)\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - A track can have multiple artists\n",
    "#   - Keeping a list can be useful for later analysis/debugging\n",
    "track_to_artists = (\n",
    "    rta.groupby(\"track_id\")[\"artist_id\"]\n",
    "       .apply(list)\n",
    "       .reset_index()\n",
    "       .rename(columns={\"artist_id\": \"artist_ids\"})\n",
    ")\n",
    "track_df = track_df.merge(track_to_artists, on=\"track_id\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Aggregate artist statistics per track\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Artist popularity/followers often correlate with track reach\n",
    "#   - For multi-artist tracks, we aggregate to stable numeric features\n",
    "artist_feat = artists.rename(\n",
    "    columns={\"id\": \"artist_id\", \"popularity\": \"artist_popularity\", \"followers\": \"artist_followers\"}\n",
    ")\n",
    "rta_art = rta.merge(artist_feat, on=\"artist_id\", how=\"left\")\n",
    "\n",
    "artist_agg = (\n",
    "    rta_art.groupby(\"track_id\")\n",
    "           .agg(\n",
    "               n_artists=(\"artist_id\", \"nunique\"),\n",
    "               artist_popularity_mean=(\"artist_popularity\", \"mean\"),\n",
    "               artist_popularity_max=(\"artist_popularity\", \"max\"),\n",
    "               artist_followers_mean=(\"artist_followers\", \"mean\"),\n",
    "               artist_followers_max=(\"artist_followers\", \"max\"),\n",
    "           )\n",
    "           .reset_index()\n",
    ")\n",
    "track_df = track_df.merge(artist_agg, on=\"track_id\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Track -> Genres (via artist genres), union per track\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Genres are usually attached to artists\n",
    "#   - We derive a track-level genre profile by taking the union across its artists\n",
    "#\n",
    "# Note:\n",
    "#   - We store genre IDs because they are stable keys.\n",
    "#   - Later you can convert to names or multi-hot encode Top-K genres.\n",
    "rag2 = rag.copy()\n",
    "if \"genre_id\" not in rag2.columns and \"id\" in rag2.columns:\n",
    "    rag2 = rag2.rename(columns={\"id\": \"genre_id\"})\n",
    "\n",
    "# Build artist -> [genre_id] list\n",
    "artist_to_genres = (\n",
    "    rag2.groupby(\"artist_id\")[\"genre_id\"]\n",
    "        .apply(lambda x: sorted(set([g for g in x.dropna().tolist()])))\n",
    "        .reset_index()\n",
    "        .rename(columns={\"genre_id\": \"artist_genres\"})\n",
    ")\n",
    "\n",
    "# Join artist genres into track-artist mapping, then union genres per track\n",
    "rta_gen = rta.merge(artist_to_genres, on=\"artist_id\", how=\"left\")\n",
    "track_to_genres = (\n",
    "    rta_gen.groupby(\"track_id\")[\"artist_genres\"]\n",
    "           .apply(lambda rows: sorted(set([g for lst in rows.dropna()\n",
    "                                          for g in (lst if isinstance(lst, list) else [])])))\n",
    "           .reset_index()\n",
    "           .rename(columns={\"artist_genres\": \"track_genres\"})\n",
    ")\n",
    "track_df = track_df.merge(track_to_genres, on=\"track_id\", how=\"left\")\n",
    "\n",
    "# Ensure list type (important when loading from CSV where lists may become strings)\n",
    "track_df[\"track_genres\"] = ensure_list_column(col_or_na(track_df, \"track_genres\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Feature Engineering (binary flags, text-derived, log transforms)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Preview availability: a simple content/availability indicator\n",
    "track_df[\"has_preview\"] = col_or_na(track_df, \"preview_url\").notna().astype(\"int8\")\n",
    "\n",
    "# Track name features: cheap but sometimes useful\n",
    "track_df[\"name_len\"] = safe_len_series(col_or_na(track_df, \"name\"))\n",
    "track_df[\"name_words\"] = safe_word_count_series(col_or_na(track_df, \"name\"))\n",
    "\n",
    "# Duration robust handling: datasets often have duration_ms instead of duration\n",
    "dur_col = \"duration\" if \"duration\" in track_df.columns else (\"duration_ms\" if \"duration_ms\" in track_df.columns else None)\n",
    "track_df[\"log_duration\"] = log1p_numeric(track_df[dur_col]) if dur_col else pd.Series(np.nan, index=track_df.index)\n",
    "\n",
    "# Followers are heavy-tailed -> log helps stabilize scale\n",
    "track_df[\"log_artist_followers_max\"] = log1p_numeric(col_or_na(track_df, \"artist_followers_max\"))\n",
    "track_df[\"log_artist_followers_mean\"] = log1p_numeric(col_or_na(track_df, \"artist_followers_mean\"))\n",
    "\n",
    "# Indicator whether audio features are present (helps model handle missingness)\n",
    "track_df[\"has_audio_features\"] = col_or_na(track_df, \"audio_feature_id\").notna().astype(\"int8\")\n",
    "\n",
    "print(\"Track-level dataset shape:\", track_df.shape)\n",
    "track_df.head(3)"
   ],
   "id": "c878d632e22819d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track-level dataset shape: (294618, 56)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                 track_id  disc_number  duration  explicit        audio_feature_id                                   name  track_number  popularity  has_preview  is_long_track  \\\n",
       "0  2DZN6ceJ7fMU2X6YWuIGHk            1    285053     False  2DZN6ceJ7fMU2X6YWuIGHk                     Toccada del 3 Tono            14           0            0              0   \n",
       "1  1dizvxctg9dHEyaYTFufVi            1    275893      True  1dizvxctg9dHEyaYTFufVi  Gz And Hustlas (feat. Nancy Fletcher)            12           0            0              0   \n",
       "2  2g8HN35AnVGIk7B8yMucww            1    252746      True  2g8HN35AnVGIk7B8yMucww              Big Poppa - 2005 Remaster            13          77            0              0   \n",
       "\n",
       "   is_tracknum_extreme  is_multidisc  is_disc_extreme  acousticness                                       analysis_url  danceability  duration_af  energy  instrumentalness  key  \\\n",
       "0                    0             0                0         0.621  https://api.spotify.com/v1/audio-analysis/2DZN...         0.147     285053.0   0.148             0.282    7   \n",
       "1                    0             0                0         0.164  https://api.spotify.com/v1/audio-analysis/1diz...         0.652     275893.0   0.814             0.000    1   \n",
       "2                    0             0                0         0.430  https://api.spotify.com/v1/audio-analysis/2g8H...         0.780     252747.0   0.575             0.000    9   \n",
       "\n",
       "   liveness  loudness  mode  speechiness      tempo  time_signature  valence  is_time_signature_rare  is_tempo_extreme  is_loudness_very_low  is_af_long  is_high_speech  \\\n",
       "0     0.151   -21.444     1       0.0324  80.634003               3   0.0367                     0.0               0.0                   0.0         0.0             0.0   \n",
       "1     0.360    -4.901     1       0.3100  91.888000               4   0.7880                     0.0               0.0                   0.0         0.0             0.0   \n",
       "2     0.143    -7.247     0       0.2730  84.491997               4   0.7730                     0.0               0.0                   0.0         0.0             0.0   \n",
       "\n",
       "   is_instrumental                album_id                                         name_album album_type   release_date  album_popularity release_date_parsed  \\\n",
       "0              0.0  5v0bDDSl25qgrxOzxqoWXJ  Pedro Ruimonte en Bruselas (Música en la Corte...      album  1509062400000                 3          2017-10-27   \n",
       "1              0.0                    <NA>                                               <NA>       <NA>           <NA>              <NA>                 NaT   \n",
       "2              0.0  2HTbQ0RHwukKVXAlTmCZP2                        Ready to Die (The Remaster)      album   779414400000                81          1994-09-13   \n",
       "\n",
       "   is_release_year_invalid  release_year  release_month  release_decade                                         artist_ids  n_artists  artist_popularity_mean  \\\n",
       "0                      0.0          2017             10            2010  [6xadlZzmcIMmgspceWCkt3, 0HWL7UfTuSRYVCrvTW5tj...          4                    8.75   \n",
       "1                      NaN          <NA>           <NA>            <NA>   [7hJcb9fa4alzcOq3EaNPoG, 3E2vuvr0IQbReTbXw2MhX8]          2                    65.5   \n",
       "2                      0.0          1994              9            1990                           [5me0Irg2ANcsgc93uaYrpb]          1                    83.0   \n",
       "\n",
       "   artist_popularity_max  artist_followers_mean  artist_followers_max                                       track_genres  name_len  name_words  log_duration  \\\n",
       "0                     15                  112.5                   390                                   [musica antigua]        18           4     12.560434   \n",
       "1                     87              3416346.5               6831895  [g funk, gangster rap, hip hop, pop rap, rap, ...        37           6     12.527772   \n",
       "2                     83              6258716.0               6258716  [east coast hip hop, gangster rap, hardcore hi...        25           5     12.440144   \n",
       "\n",
       "   log_artist_followers_max  log_artist_followers_mean  has_audio_features  \n",
       "0                  5.968708                   4.731803                   1  \n",
       "1                 15.737113                  15.044083                   1  \n",
       "2                 15.649486                  15.649486                   1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>duration</th>\n",
       "      <th>explicit</th>\n",
       "      <th>audio_feature_id</th>\n",
       "      <th>name</th>\n",
       "      <th>track_number</th>\n",
       "      <th>popularity</th>\n",
       "      <th>has_preview</th>\n",
       "      <th>is_long_track</th>\n",
       "      <th>is_tracknum_extreme</th>\n",
       "      <th>is_multidisc</th>\n",
       "      <th>is_disc_extreme</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_af</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>is_time_signature_rare</th>\n",
       "      <th>is_tempo_extreme</th>\n",
       "      <th>is_loudness_very_low</th>\n",
       "      <th>is_af_long</th>\n",
       "      <th>is_high_speech</th>\n",
       "      <th>is_instrumental</th>\n",
       "      <th>album_id</th>\n",
       "      <th>name_album</th>\n",
       "      <th>album_type</th>\n",
       "      <th>release_date</th>\n",
       "      <th>album_popularity</th>\n",
       "      <th>release_date_parsed</th>\n",
       "      <th>is_release_year_invalid</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_decade</th>\n",
       "      <th>artist_ids</th>\n",
       "      <th>n_artists</th>\n",
       "      <th>artist_popularity_mean</th>\n",
       "      <th>artist_popularity_max</th>\n",
       "      <th>artist_followers_mean</th>\n",
       "      <th>artist_followers_max</th>\n",
       "      <th>track_genres</th>\n",
       "      <th>name_len</th>\n",
       "      <th>name_words</th>\n",
       "      <th>log_duration</th>\n",
       "      <th>log_artist_followers_max</th>\n",
       "      <th>log_artist_followers_mean</th>\n",
       "      <th>has_audio_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2DZN6ceJ7fMU2X6YWuIGHk</td>\n",
       "      <td>1</td>\n",
       "      <td>285053</td>\n",
       "      <td>False</td>\n",
       "      <td>2DZN6ceJ7fMU2X6YWuIGHk</td>\n",
       "      <td>Toccada del 3 Tono</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2DZN...</td>\n",
       "      <td>0.147</td>\n",
       "      <td>285053.0</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.282</td>\n",
       "      <td>7</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-21.444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>80.634003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5v0bDDSl25qgrxOzxqoWXJ</td>\n",
       "      <td>Pedro Ruimonte en Bruselas (Música en la Corte...</td>\n",
       "      <td>album</td>\n",
       "      <td>1509062400000</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>[6xadlZzmcIMmgspceWCkt3, 0HWL7UfTuSRYVCrvTW5tj...</td>\n",
       "      <td>4</td>\n",
       "      <td>8.75</td>\n",
       "      <td>15</td>\n",
       "      <td>112.5</td>\n",
       "      <td>390</td>\n",
       "      <td>[musica antigua]</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>12.560434</td>\n",
       "      <td>5.968708</td>\n",
       "      <td>4.731803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1dizvxctg9dHEyaYTFufVi</td>\n",
       "      <td>1</td>\n",
       "      <td>275893</td>\n",
       "      <td>True</td>\n",
       "      <td>1dizvxctg9dHEyaYTFufVi</td>\n",
       "      <td>Gz And Hustlas (feat. Nancy Fletcher)</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1diz...</td>\n",
       "      <td>0.652</td>\n",
       "      <td>275893.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360</td>\n",
       "      <td>-4.901</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>91.888000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[7hJcb9fa4alzcOq3EaNPoG, 3E2vuvr0IQbReTbXw2MhX8]</td>\n",
       "      <td>2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>87</td>\n",
       "      <td>3416346.5</td>\n",
       "      <td>6831895</td>\n",
       "      <td>[g funk, gangster rap, hip hop, pop rap, rap, ...</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>12.527772</td>\n",
       "      <td>15.737113</td>\n",
       "      <td>15.044083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2g8HN35AnVGIk7B8yMucww</td>\n",
       "      <td>1</td>\n",
       "      <td>252746</td>\n",
       "      <td>True</td>\n",
       "      <td>2g8HN35AnVGIk7B8yMucww</td>\n",
       "      <td>Big Poppa - 2005 Remaster</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2g8H...</td>\n",
       "      <td>0.780</td>\n",
       "      <td>252747.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-7.247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>84.491997</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2HTbQ0RHwukKVXAlTmCZP2</td>\n",
       "      <td>Ready to Die (The Remaster)</td>\n",
       "      <td>album</td>\n",
       "      <td>779414400000</td>\n",
       "      <td>81</td>\n",
       "      <td>1994-09-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1994</td>\n",
       "      <td>9</td>\n",
       "      <td>1990</td>\n",
       "      <td>[5me0Irg2ANcsgc93uaYrpb]</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83</td>\n",
       "      <td>6258716.0</td>\n",
       "      <td>6258716</td>\n",
       "      <td>[east coast hip hop, gangster rap, hardcore hi...</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12.440144</td>\n",
       "      <td>15.649486</td>\n",
       "      <td>15.649486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Album-Level Dataset (eine Zeile = ein Album)\n",
    "\n",
    "**Ziel:** Wir bauen eine ML-fertige Tabelle, in der **jede Zeile ein Album** repräsentiert.\n",
    "Da ein Album aus vielen Tracks besteht und oft mehrere Artists hat, erzeugen wir vor allem **Aggregations-Features**.\n",
    "\n",
    "### Was passiert hier genau?\n",
    "\n",
    "1. **Album-Stammdaten + Release-Time-Features**\n",
    "   - Wir starten mit `albums` (Album-Metadaten).\n",
    "   - Wir parsen `release_date_parsed` und erzeugen daraus:\n",
    "     - `release_year`, `release_month`, `release_decade`\n",
    "\n",
    "2. **Album-Größe (Track-Anzahl)**\n",
    "   - Über `r_albums_tracks` zählen wir:\n",
    "     - `n_tracks` = Anzahl eindeutiger Tracks pro Album\n",
    "   - Das ist ein starkes Strukturfeature (Singles/EPs vs. Alben).\n",
    "\n",
    "3. **Album-Audio-Profil (Aggregierte Track-Audio-Features)**\n",
    "   - Über alle Tracks eines Albums aggregieren wir Audio-Features:\n",
    "     - z. B. `album_mean_energy`, `album_mean_danceability`, `album_mean_loudness`, `album_mean_tempo`\n",
    "   - Dadurch entsteht eine „Audio-Signatur“ des Albums.\n",
    "\n",
    "4. **Album-Artist-Profil (falls `r_albums_artists` vorhanden)**\n",
    "   - Ein Album kann mehrere Artists haben.\n",
    "   - Wir aggregieren Artists pro Album:\n",
    "     - `n_album_artists`\n",
    "     - Popularity/Follower Mittelwert und Maximum\n",
    "\n",
    "5. **Album-Genre-Profil (Union der Genres der Album-Artists)**\n",
    "   - Genres kommen typischerweise von Artists.\n",
    "   - Wir bilden `album_genres` als Vereinigung aller Artist-Genres im Album.\n",
    "\n",
    "6. **Feature Engineering**\n",
    "   - `log_n_tracks`: log-transform gegen Schiefe\n",
    "   - `name_len`, `name_words`: simple Text-Features aus Albumname\n",
    "\n",
    "**Ergebnis:** `album_df` ist eine Album-Feature-Matrix"
   ],
   "id": "10d96e4f70b21b5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:40:30.698312Z",
     "start_time": "2025-12-23T09:40:12.984055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Start from album master data + parse dates\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Album-level tasks (e.g., album popularity regression) need a single row per album\n",
    "#   - Release time features capture era effects and time bias\n",
    "\n",
    "album_df=albums.copy()\n",
    "album_df=album_df.rename(columns={\"id\": \"album_id\"})\n",
    "\n",
    "album_df[\"release_date_parsed\"] = pd.to_datetime(\n",
    "    col_or_na(album_df,\"release_date_parsed\"), errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Add derived time features: year / month / decade\n",
    "album_df = add_release_time_features(album_df, \"release_date_parsed\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Album size feature: number of tracks per album\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Singles/EPs vs albums differ structurally (track count)\n",
    "#   - Useful as a predictor and for data sanity checks\n",
    "album_track_counts = (\n",
    "    rat.groupby(\"album_id\")[\"track_id\"]\n",
    "       .nunique()\n",
    "       .reset_index()\n",
    "       .rename(columns={\"track_id\": \"n_tracks\"})\n",
    ")\n",
    "\n",
    "# Fixed merge: both sides use album_id\n",
    "album_df = album_df.merge(album_track_counts, on=\"album_id\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Album audio signature: mean of track audio features\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Albums consist of multiple tracks; we aggregate to get a stable album-level profile\n",
    "#   - Mean is a strong baseline aggregation (you could also add std/min/max later)\n",
    "POLICY_AUDIO = [\n",
    "    \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\",\n",
    "    \"speechiness\", \"valence\", \"loudness\", \"tempo\"\n",
    "]\n",
    "\n",
    "# Keep only audio columns that exist (robust to schema differences)\n",
    "audio_cols_present = [c for c in POLICY_AUDIO if c in track_df.columns]\n",
    "\n",
    "# Join album-track relation to track audio features\n",
    "rat_track_audio = rat.merge(track_df[[\"track_id\"] + audio_cols_present], on=\"track_id\", how=\"left\")\n",
    "\n",
    "# Aggregate per album (mean)\n",
    "album_audio_agg = rat_track_audio.groupby(\"album_id\")[audio_cols_present].mean().reset_index()\n",
    "\n",
    "# Prefix columns so they are clearly album-aggregates\n",
    "album_audio_agg = album_audio_agg.add_prefix(\"album_mean_\").rename(columns={\"album_mean_album_id\": \"album_id\"})\n",
    "\n",
    "# Merge audio aggregates back to album table\n",
    "album_df = album_df.merge(album_audio_agg, on=\"album_id\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Album -> artists aggregates (optional)\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Albums can have multiple artists; their popularity/followers often influence album success\n",
    "#   - This block runs only if r_albums_artists exists in your export\n",
    "if not raa.empty and \"album_id\" in raa.columns and \"artist_id\" in raa.columns:\n",
    "    raa_art = raa.merge(artist_feat, on=\"artist_id\", how=\"left\")\n",
    "\n",
    "    album_artist_agg = (\n",
    "        raa_art.groupby(\"album_id\")\n",
    "              .agg(\n",
    "                  n_album_artists=(\"artist_id\", \"nunique\"),\n",
    "                  album_artist_popularity_mean=(\"artist_popularity\", \"mean\"),\n",
    "                  album_artist_popularity_max=(\"artist_popularity\", \"max\"),\n",
    "                  album_artist_followers_mean=(\"artist_followers\", \"mean\"),\n",
    "                  album_artist_followers_max=(\"artist_followers\", \"max\"),\n",
    "              )\n",
    "              .reset_index()\n",
    "    )\n",
    "\n",
    "    album_df = album_df.merge(album_artist_agg, on=\"album_id\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Album genres union\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Spotify-like schemas often attach genres to artists\n",
    "#   - We derive an album's genre profile as the union of all album artists' genres\n",
    "if not raa.empty:\n",
    "    raa_gen = raa.merge(artist_to_genres, on=\"artist_id\", how=\"left\")\n",
    "\n",
    "    album_to_genres = (\n",
    "        raa_gen.groupby(\"album_id\")[\"artist_genres\"]\n",
    "              .apply(lambda rows: sorted(set([\n",
    "                  g for lst in rows.dropna()\n",
    "                  for g in (lst if isinstance(lst, list) else [])\n",
    "              ])))\n",
    "              .reset_index()\n",
    "              .rename(columns={\"artist_genres\": \"album_genres\"})\n",
    "    )\n",
    "\n",
    "    album_df = album_df.merge(album_to_genres, on=\"album_id\", how=\"left\")\n",
    "else:\n",
    "    # Keep a consistent schema even if we can't compute genres\n",
    "    album_df[\"album_genres\"] = [[] for _ in range(len(album_df))]\n",
    "\n",
    "# Ensure list type (important for CSV fallback)\n",
    "album_df[\"album_genres\"] = ensure_list_column(col_or_na(album_df, \"album_genres\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Feature engineering (log transforms, name features)\n",
    "# ------------------------------------------------------------\n",
    "# log transform track count (often heavy-tailed: singles vs compilations)\n",
    "album_df[\"log_n_tracks\"] = log1p_numeric(col_or_na(album_df, \"n_tracks\"))\n",
    "\n",
    "# Simple text features from album name\n",
    "album_df[\"name_len\"] = safe_len_series(col_or_na(album_df, \"name\"))\n",
    "album_df[\"name_words\"] = safe_word_count_series(col_or_na(album_df, \"name\"))\n",
    "\n",
    "print(\"Album-level dataset shape:\", album_df.shape)\n",
    "album_df.head(3)"
   ],
   "id": "138d08a7bf5bb238",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album-level dataset shape: (129152, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                 album_id                                             name album_type   release_date  popularity release_date_parsed  is_release_year_invalid  release_year  \\\n",
       "0  7zr66qWybr1mAMSUVVosKU                                          Reflexo      album  1464220800000          53          2016-05-26                        0          2016   \n",
       "1  7zrLd0zddHOwA9DGlsDr4h                                   Floating World      album  1410652800000           0          2014-09-14                        0          2014   \n",
       "2  7zri1pX9eMh0IqwpxMxOwp  Arne Aano's Beste - Slepp Himlen I Sjela Di Inn      album  1236729600000          13          2009-03-11                        0          2009   \n",
       "\n",
       "   release_month  release_decade  n_tracks  album_mean_acousticness  album_mean_danceability  album_mean_energy  album_mean_instrumentalness  album_mean_liveness  \\\n",
       "0              5            2010         1                 0.519000                    0.726              0.491                     0.000007               0.0965   \n",
       "1              9            2010         1                 0.000516                    0.335              0.823                     0.331000               0.2130   \n",
       "2              3            2000         1                 0.888000                    0.537              0.303                     0.000000               0.1350   \n",
       "\n",
       "   album_mean_speechiness  album_mean_valence  album_mean_loudness  album_mean_tempo  n_album_artists  album_artist_popularity_mean  album_artist_popularity_max  \\\n",
       "0                  0.1260              0.2870              -11.166        109.935997              1.0                          51.0                           51   \n",
       "1                  0.0437              0.0699               -7.041         90.175003              1.0                           0.0                            0   \n",
       "2                  0.0365              0.5410               -9.413        137.932007              1.0                           0.0                            0   \n",
       "\n",
       "   album_artist_followers_mean  album_artist_followers_max      album_genres  log_n_tracks  name_len  name_words  \n",
       "0                     147089.0                      147089    [hip hop tuga]      0.693147         7           1  \n",
       "1                         75.0                          75  [crossover prog]      0.693147        14           2  \n",
       "2                          0.0                           0                []      0.693147        47          10  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>name</th>\n",
       "      <th>album_type</th>\n",
       "      <th>release_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date_parsed</th>\n",
       "      <th>is_release_year_invalid</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_decade</th>\n",
       "      <th>n_tracks</th>\n",
       "      <th>album_mean_acousticness</th>\n",
       "      <th>album_mean_danceability</th>\n",
       "      <th>album_mean_energy</th>\n",
       "      <th>album_mean_instrumentalness</th>\n",
       "      <th>album_mean_liveness</th>\n",
       "      <th>album_mean_speechiness</th>\n",
       "      <th>album_mean_valence</th>\n",
       "      <th>album_mean_loudness</th>\n",
       "      <th>album_mean_tempo</th>\n",
       "      <th>n_album_artists</th>\n",
       "      <th>album_artist_popularity_mean</th>\n",
       "      <th>album_artist_popularity_max</th>\n",
       "      <th>album_artist_followers_mean</th>\n",
       "      <th>album_artist_followers_max</th>\n",
       "      <th>album_genres</th>\n",
       "      <th>log_n_tracks</th>\n",
       "      <th>name_len</th>\n",
       "      <th>name_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7zr66qWybr1mAMSUVVosKU</td>\n",
       "      <td>Reflexo</td>\n",
       "      <td>album</td>\n",
       "      <td>1464220800000</td>\n",
       "      <td>53</td>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>-11.166</td>\n",
       "      <td>109.935997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51</td>\n",
       "      <td>147089.0</td>\n",
       "      <td>147089</td>\n",
       "      <td>[hip hop tuga]</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7zrLd0zddHOwA9DGlsDr4h</td>\n",
       "      <td>Floating World</td>\n",
       "      <td>album</td>\n",
       "      <td>1410652800000</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-14</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>-7.041</td>\n",
       "      <td>90.175003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75</td>\n",
       "      <td>[crossover prog]</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7zri1pX9eMh0IqwpxMxOwp</td>\n",
       "      <td>Arne Aano's Beste - Slepp Himlen I Sjela Di Inn</td>\n",
       "      <td>album</td>\n",
       "      <td>1236729600000</td>\n",
       "      <td>13</td>\n",
       "      <td>2009-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>-9.413</td>\n",
       "      <td>137.932007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Artist-Level Dataset (eine Zeile = ein Artist)\n",
    "\n",
    "**Ziel:** Wir bauen eine ML-fertige Tabelle, in der **jede Zeile einen Artist** repräsentiert.\n",
    "Diese Tabelle wird vor allem für **Clustering / Community Detection** (unsupervised) genutzt, kann aber später auch für supervised Tasks (z. B. Artist-Popularity) verwendet werden.\n",
    "\n",
    "### Was passiert hier genau?\n",
    "\n",
    "1. **Artist-Stammdaten**\n",
    "   - Wir starten mit `artists` und benennen die ID-Spalte zu `artist_id`, damit Joins konsistent sind.\n",
    "\n",
    "2. **Artist-Style-Profil aus Tracks (Aggregation)**\n",
    "   - Über `r_track_artist` verknüpfen wir Artists mit ihren Tracks.\n",
    "   - Wir hängen die Track-Features an (Audio + optional Popularity/Explicit) und aggregieren dann pro Artist:\n",
    "     - `n_tracks`: Anzahl eindeutiger Tracks\n",
    "     - `track_pop_mean`: durchschnittliche Track-Popularität (falls vorhanden)\n",
    "     - `explicit_rate`: Anteil „explicit“-Tracks (falls vorhanden)\n",
    "     - `mean_<audio_feature>`: durchschnittliche Audio-Signatur (z. B. mean_energy, mean_danceability, …)\n",
    "\n",
    "   Ergebnis: Jeder Artist bekommt einen stabilen numerischen Vektor, der seinen „Sound“ beschreibt.\n",
    "\n",
    "3. **Genres pro Artist**\n",
    "   - Wir mergen die Liste der Genres (`artist_genres`) pro Artist (aus `r_artist_genre`).\n",
    "   - Diese Liste kann später z. B. als Multi-Hot-Features genutzt werden.\n",
    "\n",
    "4. **Feature Engineering**\n",
    "   - `log_followers`: Log-Transform für heavy-tailed Followers\n",
    "   - `log_n_tracks`: Log-Transform, da Track-Anzahl oft sehr schief verteilt ist\n",
    "\n",
    "**Ergebnis:** `artist_df` enthält pro Artist:\n",
    "- Stammdaten (name, popularity, followers, …)\n",
    "- Aggregierte Track-Audio-Signatur\n",
    "- Genre-Liste\n",
    "- log-transformierte Stabilitätsfeatures\n"
   ],
   "id": "6301de187e1db68c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:07.478012Z",
     "start_time": "2025-12-23T09:40:30.744985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1) Start from artist master data\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - We want a single vector per artist for clustering / similarity analysis\n",
    "#   - Rename PK to artist_id for consistent joins across tables\n",
    "artist_df = artists.rename(columns={\"id\": \"artist_id\"}).copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Build artist \"style profile\" by aggregating over all their tracks\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Artists have many tracks (Many-to-Many: r_track_artist)\n",
    "#   - We want stable numeric features per artist:\n",
    "#       * number of tracks\n",
    "#       * average audio signature (mean_energy, mean_danceability, ...)\n",
    "#       * optionally: average track popularity and explicit rate\n",
    "cols_for_artist_agg = [\"track_id\"] + audio_cols_present\n",
    "\n",
    "if \"popularity\" in track_df.columns:\n",
    "    cols_for_artist_agg += [\"popularity\"]\n",
    "\n",
    "if \"explicit\" in track_df.columns:\n",
    "    cols_for_artist_agg += [\"explicit\"]\n",
    "\n",
    "rta_track_audio = rta.merge(track_df[cols_for_artist_agg], on=\"track_id\", how=\"left\")\n",
    "\n",
    "\n",
    "# Helper explicit rate per artist\n",
    "\n",
    "def explicit_rate_fn(x):\n",
    "    xx = pd.to_numeric(x,errors=\"coerce\")\n",
    "    if xx.dropna().empty:\n",
    "        return np.nan\n",
    "    return float(np.nanmean(xx))\n",
    "\n",
    "agg_dict = {\n",
    "    \"n_tracks\":(\"track_id\",\"nunique\")\n",
    "}\n",
    "\n",
    "# Optional: average track popularity (proxy of how popular their tracks tend to be)\n",
    "if \"popularity\" in rta_track_audio.columns:\n",
    "    agg_dict[\"track_pop_mean\"] = (\"popularity\", \"mean\")\n",
    "\n",
    "# Optional: explicit rate (share of explicit tracks)\n",
    "if \"explicit\" in rta_track_audio.columns:\n",
    "    agg_dict[\"explicit_rate\"] = (\"explicit\", explicit_rate_fn)\n",
    "\n",
    "# Core: mean audio signature per artist\n",
    "for c in audio_cols_present:\n",
    "    agg_dict[f\"mean_{c}\"] = (c, \"mean\")\n",
    "\n",
    "artist_audio_agg = (\n",
    "    rta_track_audio.groupby(\"artist_id\")\n",
    "    .agg(**agg_dict)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge aggregated features back into artist table\n",
    "artist_df = artist_df.merge(artist_audio_agg, on=\"artist_id\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Attach genres list per artist\n",
    "# ------------------------------------------------------------\n",
    "# Why:\n",
    "#   - Genres are usually provided at artist-level\n",
    "#   - We keep them as list for later multi-hot encoding (Top-K)\n",
    "artist_df = artist_df.merge(artist_to_genres, on=\"artist_id\", how=\"left\")\n",
    "artist_df[\"artist_genres\"] = ensure_list_column(col_or_na(artist_df, \"artist_genres\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Feature engineering (log transforms for heavy-tailed counts)\n",
    "# ------------------------------------------------------------\n",
    "# followers and track counts are typically very skewed -> log stabilizes scale\n",
    "artist_df[\"log_followers\"] = log1p_numeric(col_or_na(artist_df, \"followers\"))\n",
    "artist_df[\"log_n_tracks\"] = log1p_numeric(col_or_na(artist_df, \"n_tracks\"))\n",
    "\n",
    "print(\"Artist-level dataset shape:\", artist_df.shape)\n",
    "artist_df.head(3)\n"
   ],
   "id": "d2c3fc683ac6e877",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist-level dataset shape: (139608, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                artist_id              name  popularity  followers  is_followers_extreme  followers_log1p  n_tracks  track_pop_mean  explicit_rate  mean_acousticness  \\\n",
       "0  7zzl8HQ2v9hVdLh0Ygkwgc        Megatherio           2         59                     0         4.094345         3             2.0            1.0           0.000101   \n",
       "1  00045gNg7mLEf9UY9yhD0t  Kubus & BangBang          13        820                     0         6.710523        11        5.727273            1.0           0.121626   \n",
       "2  000xagx3GkcunHTFdB4ly0              Moxa           0        156                     0         5.056246         1             0.0            0.0           0.000151   \n",
       "\n",
       "   mean_danceability  mean_energy  mean_instrumentalness  mean_liveness  mean_speechiness  mean_valence  mean_loudness  mean_tempo             artist_genres  log_followers  \\\n",
       "0           0.267333        0.990               0.013101       0.104633            0.0902      0.311900      -4.583000  136.755666  [brazilian thrash metal]       4.094345   \n",
       "1           0.658273        0.651               0.000177       0.246955            0.3073      0.497918      -8.265273  122.092817           [dutch hip hop]       6.710523   \n",
       "2           0.441000        0.959               0.334000       0.229000            0.0611      0.171000      -4.694000  138.009003               [indie emo]       5.056246   \n",
       "\n",
       "   log_n_tracks  \n",
       "0      1.386294  \n",
       "1      2.484907  \n",
       "2      0.693147  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>followers</th>\n",
       "      <th>is_followers_extreme</th>\n",
       "      <th>followers_log1p</th>\n",
       "      <th>n_tracks</th>\n",
       "      <th>track_pop_mean</th>\n",
       "      <th>explicit_rate</th>\n",
       "      <th>mean_acousticness</th>\n",
       "      <th>mean_danceability</th>\n",
       "      <th>mean_energy</th>\n",
       "      <th>mean_instrumentalness</th>\n",
       "      <th>mean_liveness</th>\n",
       "      <th>mean_speechiness</th>\n",
       "      <th>mean_valence</th>\n",
       "      <th>mean_loudness</th>\n",
       "      <th>mean_tempo</th>\n",
       "      <th>artist_genres</th>\n",
       "      <th>log_followers</th>\n",
       "      <th>log_n_tracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7zzl8HQ2v9hVdLh0Ygkwgc</td>\n",
       "      <td>Megatherio</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.267333</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>0.104633</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>-4.583000</td>\n",
       "      <td>136.755666</td>\n",
       "      <td>[brazilian thrash metal]</td>\n",
       "      <td>4.094345</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00045gNg7mLEf9UY9yhD0t</td>\n",
       "      <td>Kubus &amp; BangBang</td>\n",
       "      <td>13</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "      <td>6.710523</td>\n",
       "      <td>11</td>\n",
       "      <td>5.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121626</td>\n",
       "      <td>0.658273</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.246955</td>\n",
       "      <td>0.3073</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>-8.265273</td>\n",
       "      <td>122.092817</td>\n",
       "      <td>[dutch hip hop]</td>\n",
       "      <td>6.710523</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000xagx3GkcunHTFdB4ly0</td>\n",
       "      <td>Moxa</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>5.056246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>-4.694000</td>\n",
       "      <td>138.009003</td>\n",
       "      <td>[indie emo]</td>\n",
       "      <td>5.056246</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save modeling datasets",
   "id": "41d4accd859b105e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:12.693645Z",
     "start_time": "2025-12-23T09:41:07.549021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "track_out = PATHS.modeling_dir / \"track_dataset.parquet\"\n",
    "album_out = PATHS.modeling_dir / \"album_dataset.parquet\"\n",
    "artist_out = PATHS.modeling_dir / \"artist_dataset.parquet\"\n",
    "\n",
    "track_df.to_parquet(track_out, index=False)\n",
    "album_df.to_parquet(album_out, index=False)\n",
    "artist_df.to_parquet(artist_out, index=False)\n",
    "\n",
    "print(\" Saved modeling datasets:\")\n",
    "print(\" -\", track_out)\n",
    "print(\" -\", album_out)\n",
    "print(\" -\", artist_out)"
   ],
   "id": "8ea9d7259000d77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved modeling datasets:\n",
      " - ..\\data\\processed\\modeling\\track_dataset.parquet\n",
      " - ..\\data\\processed\\modeling\\album_dataset.parquet\n",
      " - ..\\data\\processed\\modeling\\artist_dataset.parquet\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#  Targets\n",
    "   In this section we construct all targets used in this project:\n",
    "   (A) Track popularity regression target (continuous)\n",
    "   (B) Album popularity regression target (continuous)\n",
    "   (C) Hit prediction target (binary) using year-relative threshold\n",
    "   (D) Explicit/content target (binary)\n",
    "   (E) Mood tags target (multi-label; weak supervision via audio feature quantiles)\n",
    "\n",
    " Why separate targets from features?\n",
    " - Prevent leakage: targets are derived ONLY from allowed columns.\n",
    " - Reproducibility: same label definition used later (Notebook 4 scoring).\n"
   ],
   "id": "55291a885f28da7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:12.981174Z",
     "start_time": "2025-12-23T09:41:12.706525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (A) Track popularity regression\n",
    "# Popularity is typically in [0,100]. Some rows may have missing popularity -> keep as NaN and mask later.\n",
    "assert \"popularity\" in track_df.columns, \"track_df must contain 'popularity' for track popularity target\"\n",
    "y_track_pop = pd.to_numeric(track_df[\"popularity\"], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "# (B) Album popularity regression\n",
    "# Similar to tracks, popularity is the numeric target, and NaN indicates missing label.\n",
    "assert \"popularity\" in album_df.columns, \"album_df must contain 'popularity' for album popularity target\"\n",
    "y_album_pop = pd.to_numeric(album_df[\"popularity\"], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "# (C) Hit prediction (binary)\n",
    "# Default definition:\n",
    "# - A \"hit\" is defined within each release year using a percentile threshold.\n",
    "# - This is more fair than a fixed popularity threshold across decades.\n",
    "#\n",
    "# Fallback:\n",
    "# - If release_year is missing OR threshold can't be computed for a year, use HIT_FALLBACK_POP_THRESHOLD.\n",
    "\n",
    "def build_hit_labels_robust(\n",
    "    df: pd.DataFrame,\n",
    "    hit_percentile: float = 0.90,        # \"top 10%\" (within year if possible)\n",
    "    desired_rate: float = 0.10,          # safety fallback target positive rate\n",
    "    min_tracks_per_year: int = 200,      # lower this if your sample per year is small\n",
    "    use_nonzero: bool = True             # ignore popularity==0 when computing thresholds\n",
    ") -> pd.Series:\n",
    "    pop = pd.to_numeric(df[\"popularity\"], errors=\"coerce\").astype(\"float64\")\n",
    "    year = pd.to_numeric(df.get(\"release_year\", np.nan), errors=\"coerce\").round()\n",
    "\n",
    "    # ---------- global threshold (non-zero aware) ----------\n",
    "    if use_nonzero:\n",
    "        nz = pop[(pop > 0) & pop.notna()]\n",
    "    else:\n",
    "        nz = pop.dropna()\n",
    "\n",
    "    if len(nz) > 0:\n",
    "        global_thr = float(nz.quantile(hit_percentile))\n",
    "    else:\n",
    "        # if everything is 0/NaN, fall back to regular quantile\n",
    "        global_thr = float(pop.dropna().quantile(hit_percentile)) if pop.notna().any() else 0.0\n",
    "\n",
    "    # ---------- per-year thresholds (only for \"good\" years) ----------\n",
    "    y = pd.Series(np.nan, index=df.index, dtype=\"float64\")\n",
    "\n",
    "    if year.notna().any():\n",
    "        tmp = pd.DataFrame({\"year\": year, \"pop\": pop}).dropna(subset=[\"year\", \"pop\"])\n",
    "\n",
    "        # keep only years with enough rows\n",
    "        counts = tmp[\"year\"].value_counts()\n",
    "        good_years = counts[counts >= min_tracks_per_year].index\n",
    "        tmp_good = tmp[tmp[\"year\"].isin(good_years)]\n",
    "\n",
    "        if len(tmp_good) > 0:\n",
    "            def year_thr_func(s: pd.Series) -> float:\n",
    "                s = s.dropna()\n",
    "                if use_nonzero:\n",
    "                    s = s[s > 0]\n",
    "                if len(s) == 0:\n",
    "                    return np.nan\n",
    "                return float(s.quantile(hit_percentile))\n",
    "\n",
    "            year_thr = tmp_good.groupby(\"year\")[\"pop\"].apply(year_thr_func)\n",
    "            thr = year.map(year_thr)  # NaN for missing/rare years\n",
    "\n",
    "            # year rule where threshold exists\n",
    "            y = (pop >= thr).where(thr.notna(), np.nan)\n",
    "\n",
    "    # ---------- fill missing with global rule ----------\n",
    "    y = y.where(pd.notna(y), pop >= global_thr)\n",
    "\n",
    "    # finalize boolean -> int8\n",
    "    y = pd.Series(y).fillna(False).astype(bool).astype(\"int8\")\n",
    "\n",
    "    # ---------- safety: if label became one-class, force top-K globally ----------\n",
    "    if y.nunique() < 2:\n",
    "        n = int(pop.notna().sum())\n",
    "        k = max(1, int(desired_rate * n))\n",
    "\n",
    "        # Take top-k by popularity (ties handled)\n",
    "        top_idx = pop.fillna(-1).nlargest(k).index\n",
    "        y = pd.Series(0, index=df.index, dtype=\"int8\")\n",
    "        y.loc[top_idx] = 1\n",
    "\n",
    "    return y\n",
    "\n",
    "y_hit = build_hit_labels_robust(\n",
    "    track_df,\n",
    "    hit_percentile=HIT_PERCENTILE,\n",
    "    desired_rate=0.10,\n",
    "    min_tracks_per_year=200,   # if your sample per year is smaller, set 50\n",
    "    use_nonzero=True\n",
    ")\n",
    "\n",
    "print(\"Hit label distribution:\", y_hit.value_counts(dropna=False).to_dict())\n",
    "print(\"Hit positive rate:\", float(y_hit.mean()))\n",
    "\n",
    "\n",
    "# (D) Explicit prediction (binary)\n",
    "# explicit is already (0/1) in most Spotify dumps. Missing -> 0 (conservative).\n",
    "if \"explicit\" in track_df.columns:\n",
    "    y_explicit = pd.to_numeric(track_df[\"explicit\"], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "else:\n",
    "    y_explicit = pd.Series(0, index=track_df.index, dtype=\"int8\")\n",
    "\n",
    "# (E) Mood tags (multi-label)\n",
    "# We create weak supervision labels using quantiles of audio features.\n",
    "# Example: \"high_energy\" = 1 if energy is above 80th percentile.\n",
    "#\n",
    "# NOTE on evaluation:\n",
    "# - Strict: compute thresholds on TRAIN ONLY to avoid slight leakage.\n",
    "# - Demo/baseline: compute thresholds on FULL data (fast and stable).\n",
    "mood_thresholds: Dict[tuple, float] = {}\n",
    "\n",
    "for name, col, q, direction in MOOD_TAGS:\n",
    "    if col in track_df.columns:\n",
    "        vals = pd.to_numeric(track_df[col], errors=\"coerce\").dropna()\n",
    "        mood_thresholds[(name, col, q, direction)] = float(vals.quantile(q)) if len(vals) else np.nan\n",
    "    else:\n",
    "        mood_thresholds[(name, col, q, direction)] = np.nan\n",
    "\n",
    "def build_mood_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a multi-label target matrix Y_mood of shape (n_samples, n_labels).\n",
    "    Each label is derived from a threshold on an audio feature.\n",
    "    Missing audio feature values become label=0 (no evidence for tag).\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for name, col, q, direction in MOOD_TAGS:\n",
    "        if col not in df.columns:\n",
    "            out[name] = 0\n",
    "            continue\n",
    "\n",
    "        thr = mood_thresholds.get((name, col, q, direction), np.nan)\n",
    "        x = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "        if np.isnan(thr):\n",
    "            out[name] = 0\n",
    "            continue\n",
    "\n",
    "        if direction == \"gt\":\n",
    "            out[name] = (x >= thr).fillna(False).astype(\"int8\")\n",
    "        else:\n",
    "            out[name] = (x <= thr).fillna(False).astype(\"int8\")\n",
    "\n",
    "    return out\n",
    "\n",
    "Y_mood = build_mood_labels(track_df)\n",
    "\n",
    "print(\"Targets prepared:\")\n",
    "print(\" - y_track_pop:\", y_track_pop.shape, \"missing_rate:\", float(y_track_pop.isna().mean()))\n",
    "print(\" - y_album_pop:\", y_album_pop.shape, \"missing_rate:\", float(y_album_pop.isna().mean()))\n",
    "print(\" - y_hit dist:\", y_hit.value_counts(dropna=False).to_dict())\n",
    "print(\" - y_explicit dist:\", y_explicit.value_counts(dropna=False).to_dict())\n",
    "print(\" - Y_mood:\", Y_mood.shape)"
   ],
   "id": "b89f65e387bbdf66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit label distribution: {0: 246757, 1: 47861}\n",
      "Hit positive rate: 0.16245103829365484\n",
      "Targets prepared:\n",
      " - y_track_pop: (294618,) missing_rate: 0.0\n",
      " - y_album_pop: (129152,) missing_rate: 0.0\n",
      " - y_hit dist: {0: 246757, 1: 47861}\n",
      " - y_explicit dist: {0: 214945, 1: 79673}\n",
      " - Y_mood: (294618, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_31068\\3971996365.py:71: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = pd.Series(y).fillna(False).astype(bool).astype(\"int8\")\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Genre multi-hop (Top-K) for track/album/artist\n",
    "\n",
    " Genres are stored as LISTS (e.g. track_genres = [genre_id1, genre_id2, ...]).\n",
    " Most ML models need fixed-size numeric vectors, so we:\n",
    "   1) pick the Top-K most frequent genres in track_df\n",
    "   2) create a multi-hot encoding (0/1 columns) for those Top-K genres\n",
    "\n",
    " Why Top-K?\n",
    " - The full genre space can be huge.\n",
    " - Top-K keeps dimensionality reasonable and avoids sparse explosion.\n",
    " - Rare genres can be grouped into \"other\" implicitly (all zeros)."
   ],
   "id": "9f5253c720a39360"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:20.765105Z",
     "start_time": "2025-12-23T09:41:13.005079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_genres = top_k_list_counts(track_df[\"track_genres\"], top_k=TOP_K_GENRES) if \"track_genres\" in track_df.columns else []\n",
    "\n",
    "track_genre_mh = (\n",
    "    genres_to_multihot(track_df, \"track_genres\", top_genres, prefix=\"track_\")\n",
    "    if top_genres else pd.DataFrame(index=track_df.index)\n",
    ")\n",
    "album_genre_mh = (\n",
    "    genres_to_multihot(album_df, \"album_genres\", top_genres, prefix=\"album_\")\n",
    "    if (top_genres and \"album_genres\" in album_df.columns) else pd.DataFrame(index=album_df.index)\n",
    ")\n",
    "artist_genre_mh = (\n",
    "    genres_to_multihot(artist_df, \"artist_genres\", top_genres, prefix=\"artist_\")\n",
    "    if (top_genres and \"artist_genres\" in artist_df.columns) else pd.DataFrame(index=artist_df.index)\n",
    ")\n",
    "\n",
    "print(\"Genre multi-hot shapes:\", track_genre_mh.shape, album_genre_mh.shape, artist_genre_mh.shape)\n"
   ],
   "id": "963868a53a975e5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre multi-hot shapes: (294618, 50) (129152, 50) (139608, 50)\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Selection & Leakage Guards (Track + Album)\n",
    "\n",
    "In diesem Schritt entscheiden wir **welche Spalten als Model-Inputs erlaubt sind**.\n",
    "Wir trennen bewusst:\n",
    "\n",
    "- **`track_df` / `album_df`**: reichhaltige, denormalisierte Tabellen (auch mit IDs/Listen/URLs für Debugging)\n",
    "- **`X_*`**: saubere Feature-Matrizen für ML (nur numerische/categoricals + Genre-Vektoren)\n",
    "\n",
    "### Prinzipien\n",
    "\n",
    "1. **No-ID / No-URL policy**\n",
    "   - Spalten wie `track_id`, `album_id`, `audio_feature_id`, `analysis_url`, `preview_url` dürfen **niemals** in `X` landen.\n",
    "   - Sonst können Modelle über Memorization „perfekte“ Ergebnisse erzielen.\n",
    "\n",
    "2. **Task-spezifische Leakage-Regeln**\n",
    "   - Für **Popularity Regression** entfernen wir standardmäßig starke Proxy-Features wie:\n",
    "     - `album_popularity` (Track-Task)\n",
    "     - `artist_popularity_*` / `artist_followers_*` (optional, je nach Deployment-Szenario)\n",
    "   - Für andere Tasks (Hit/Explicit/Mood) gelten zusätzliche Drops (z. B. keine Popularity-Proxies beim Hit-Label).\n",
    "\n",
    "3. **Reproduzierbares Feature-Schema**\n",
    "   - Wir definieren Feature-Gruppen (numeric/categorical/genres) und erzeugen daraus konsistente `X_*` Matrizen,\n",
    "     die später auch in Notebook 4 (Inference) wiederverwendet werden können.\n"
   ],
   "id": "4f3f430196582b2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Global Switches",
   "id": "21bd9690229a1741"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:20.844453Z",
     "start_time": "2025-12-23T09:41:20.837479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ALLOW_LEAKY_FEATURES = False   # if True, allow reach/proxy features (album_popularity, artist_popularity, followers, etc.)\n",
    "ALLOW_TEXT_FEATURES  = True    # keep name_len/name_words"
   ],
   "id": "4a4ddfdbb3ccf1f6",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Universal “never allow” columns (IDs, URLs, raw lists)",
   "id": "8e88748196887675"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:20.880088Z",
     "start_time": "2025-12-23T09:41:20.871359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NEVER_FEATURE_COLS = {\n",
    "    # IDs\n",
    "    \"track_id\", \"album_id\", \"artist_id\", \"audio_feature_id\",\n",
    "    # URLs / URIs\n",
    "    \"analysis_url\", \"preview_url\", \"href\", \"uri\", \"spotify_url\",\n",
    "    # raw list columns (we will use multi-hot instead)\n",
    "    \"artist_ids\", \"track_genres\", \"album_genres\",\n",
    "    # raw names (we use name_len/name_words instead)\n",
    "    \"name\",\n",
    "    # raw dates (we use derived time features instead)\n",
    "    \"release_date_parsed\", \"release_date\",\n",
    "}\n"
   ],
   "id": "7386f833415983f0",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Track Feature Selection\n",
   "id": "97dcd9bcb02dbadb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:21.003537Z",
     "start_time": "2025-12-23T09:41:20.900923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Audio feature columns (policy-driven)\n",
    "track_audio_extra = [c for c in [\"key\", \"mode\", \"time_signature\"] if c in track_df.columns]\n",
    "track_audio_main  = [c for c in POLICY_AUDIO if c in track_df.columns]\n",
    "\n",
    "duration_feature = None\n",
    "if isinstance(dur_col, str) and dur_col.strip() and (dur_col in track_df.columns):\n",
    "    duration_feature = dur_col\n",
    "\n",
    "TRACK_NUMERIC = [\n",
    "    \"disc_number\", \"track_number\",\n",
    "    *( [duration_feature] if duration_feature else [] ),\n",
    "    \"log_duration\",\n",
    "    \"has_preview\",\n",
    "    \"has_audio_features\",\n",
    "    \"release_year\", \"release_month\", \"release_decade\",\n",
    "    \"n_artists\",\n",
    "    # reach proxies (handled by ALLOW_LEAKY_FEATURES below)\n",
    "    \"artist_popularity_mean\", \"artist_popularity_max\",\n",
    "    \"artist_followers_mean\", \"artist_followers_max\",\n",
    "    \"log_artist_followers_mean\", \"log_artist_followers_max\",\n",
    "] + track_audio_main + track_audio_extra\n",
    "\n",
    "if ALLOW_TEXT_FEATURES:\n",
    "    TRACK_NUMERIC += [\"name_len\", \"name_words\"]\n",
    "\n",
    "TRACK_CATEGORICAL = [c for c in [\"album_type\"] if c in track_df.columns]\n",
    "\n",
    "# Remove missing and forbidden cols\n",
    "TRACK_NUMERIC = [c for c in TRACK_NUMERIC if c in track_df.columns and c not in NEVER_FEATURE_COLS]\n",
    "TRACK_CATEGORICAL = [c for c in TRACK_CATEGORICAL if c in track_df.columns and c not in NEVER_FEATURE_COLS]\n",
    "\n",
    "# --- Leakage policy ---\n",
    "# album_popularity is a strong proxy for track popularity; allow only if explicitly enabled\n",
    "if \"album_popularity\" in track_df.columns and ALLOW_LEAKY_FEATURES:\n",
    "    TRACK_NUMERIC = TRACK_NUMERIC + [\"album_popularity\"]\n",
    "\n",
    "# If leakage OFF, remove reach proxies (recommended for realistic estimates)\n",
    "if not ALLOW_LEAKY_FEATURES:\n",
    "    TRACK_NUMERIC = [c for c in TRACK_NUMERIC if c not in {\n",
    "        \"artist_popularity_mean\", \"artist_popularity_max\",\n",
    "        \"artist_followers_mean\", \"artist_followers_max\",\n",
    "        \"log_artist_followers_mean\", \"log_artist_followers_max\",\n",
    "        \"album_popularity\",\n",
    "    }]\n",
    "\n",
    "# Build base X\n",
    "X_track_base = track_df[TRACK_NUMERIC + TRACK_CATEGORICAL].copy()\n",
    "\n",
    "# Append genre multi-hot if you have it\n",
    "X_track = pd.concat([X_track_base.reset_index(drop=True), track_genre_mh.reset_index(drop=True)], axis=1)"
   ],
   "id": "3f5e7a9d42e85d5c",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Task-specific TRACK matrices (and extra guards)",
   "id": "91a5ca5a07f4557d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:21.338147Z",
     "start_time": "2025-12-23T09:41:21.020865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Targets (assumed already defined)\n",
    "# y_track_pop = track_df[\"popularity\"]\n",
    "# y_hit, y_explicit, Y_mood already created\n",
    "\n",
    "# Popularity regression\n",
    "mask_track_pop = y_track_pop.notna()\n",
    "X_track_pop = X_track.loc[mask_track_pop].reset_index(drop=True)\n",
    "y_track_pop_clean = y_track_pop.loc[mask_track_pop].reset_index(drop=True)\n",
    "\n",
    "# Hit prediction: if hit label is derived from popularity, block popularity proxies always\n",
    "X_track_hit = X_track.loc[mask_track_pop].copy().reset_index(drop=True)\n",
    "y_hit_clean = y_hit.loc[mask_track_pop].reset_index(drop=True)\n",
    "\n",
    "# Explicit\n",
    "X_track_explicit = X_track.reset_index(drop=True)\n",
    "y_explicit_clean = y_explicit.reset_index(drop=True)\n",
    "\n",
    "# Mood: require audio features available\n",
    "mask_mood = (track_df[\"has_audio_features\"] == 1)\n",
    "X_track_mood = X_track.loc[mask_mood].reset_index(drop=True)\n",
    "Y_mood_clean = Y_mood.loc[mask_mood].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"X_track shapes:\")\n",
    "print(\" - pop:\", X_track_pop.shape, y_track_pop_clean.shape)\n",
    "print(\" - hit:\", X_track_hit.shape, y_hit_clean.shape)\n",
    "print(\" - explicit:\", X_track_explicit.shape, y_explicit_clean.shape)\n",
    "print(\" - mood:\", X_track_mood.shape, Y_mood_clean.shape)\n"
   ],
   "id": "47d920ef71bdb2bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_track shapes:\n",
      " - pop: (294618, 75) (294618,)\n",
      " - hit: (294618, 75) (294618,)\n",
      " - explicit: (294618, 75) (294618,)\n",
      " - mood: (294616, 75) (294616, 7)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ALBUM feature selection (clean X from rich album_df)",
   "id": "1ed537b957bdc18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:21.445409Z",
     "start_time": "2025-12-23T09:41:21.389046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Album numeric base\n",
    "ALBUM_NUMERIC = [\n",
    "    \"release_year\", \"release_month\", \"release_decade\",\n",
    "    \"n_tracks\", \"log_n_tracks\",\n",
    "]\n",
    "\n",
    "if ALLOW_TEXT_FEATURES:\n",
    "    ALBUM_NUMERIC += [\"name_len\", \"name_words\"]\n",
    "\n",
    "# Add aggregated audio + artist aggregates\n",
    "ALBUM_NUMERIC += [c for c in album_df.columns if c.startswith(\"album_mean_\")]\n",
    "ALBUM_NUMERIC += [c for c in album_df.columns if c.startswith(\"album_artist_\")]\n",
    "\n",
    "ALBUM_NUMERIC = [c for c in ALBUM_NUMERIC if c in album_df.columns and c not in NEVER_FEATURE_COLS]\n",
    "\n",
    "ALBUM_CATEGORICAL = [c for c in [\"album_type\"] if c in album_df.columns and c not in NEVER_FEATURE_COLS]\n",
    "\n",
    "# Leakage policy for albums:\n",
    "# If leakage OFF, remove album_artist reach proxies (recommended)\n",
    "if not ALLOW_LEAKY_FEATURES:\n",
    "    ALBUM_NUMERIC = [c for c in ALBUM_NUMERIC if c not in {\n",
    "        \"album_artist_popularity_mean\", \"album_artist_popularity_max\",\n",
    "        \"album_artist_followers_mean\", \"album_artist_followers_max\",\n",
    "    }]\n",
    "\n",
    "X_album_base = album_df[ALBUM_NUMERIC + ALBUM_CATEGORICAL].copy()\n",
    "\n",
    "# Append album genre multi-hot (assumes album_genre_mh aligns with album_df order)\n",
    "X_album = pd.concat([X_album_base.reset_index(drop=True), album_genre_mh.reset_index(drop=True)], axis=1)\n",
    "\n",
    "mask_album_pop = y_album_pop.notna()\n",
    "X_album_pop = X_album.loc[mask_album_pop].reset_index(drop=True)\n",
    "y_album_pop_clean = y_album_pop.loc[mask_album_pop].reset_index(drop=True)\n",
    "\n",
    "print(\"X_album_pop:\", X_album_pop.shape, y_album_pop_clean.shape)\n"
   ],
   "id": "33260369493c3461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_album_pop: (129152, 67) (129152,)\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:21.504570Z",
     "start_time": "2025-12-23T09:41:21.491411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# HARD GUARD: no forbidden columns accidentally included\n",
    "bad_cols_track = [c for c in X_track.columns if c in NEVER_FEATURE_COLS or any(k in c.lower() for k in [\"url\", \"uri\", \"href\", \"api.spotify.com\", \"id\"])]\n",
    "bad_cols_album = [c for c in X_album.columns if c in NEVER_FEATURE_COLS or any(k in c.lower() for k in [\"url\", \"uri\", \"href\", \"api.spotify.com\", \"id\"])]\n",
    "\n",
    "print(\"Forbidden columns in X_track:\", bad_cols_track[:20])\n",
    "print(\"Forbidden columns in X_album:\", bad_cols_album[:20])\n",
    "\n",
    "assert len(bad_cols_track) == 0, f\"Leakage columns found in X_track: {bad_cols_track[:10]}\"\n",
    "assert len(bad_cols_album) == 0, f\"Leakage columns found in X_album: {bad_cols_album[:10]}\"\n"
   ],
   "id": "3eb3af99ecd41882",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forbidden columns in X_track: []\n",
      "Forbidden columns in X_album: []\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:21.573142Z",
     "start_time": "2025-12-23T09:41:21.560311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------------------------------------\n",
    "# Mood-task leakage guard\n",
    "# ------------------------------------------------------------\n",
    "# These audio features are the DIRECT source of the mood labels.\n",
    "# Keeping them would allow the model to trivially reconstruct the labels.\n",
    "\n",
    "MOOD_LABEL_SOURCE_AUDIO = [\n",
    "    \"acousticness\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"speechiness\",\n",
    "    \"valence\",\n",
    "    \"loudness\",\n",
    "    \"tempo\",\n",
    "    \"key\",\n",
    "    \"mode\",\n",
    "    \"time_signature\",\n",
    "]\n",
    "\n",
    "# Apply only to mood task\n",
    "X_track_mood = X_track_mood.drop(\n",
    "    columns=[c for c in MOOD_LABEL_SOURCE_AUDIO if c in X_track_mood.columns],\n",
    "    errors=\"ignore\"\n",
    ")\n",
    "\n",
    "print(\"Mood features after leakage guard:\", X_track_mood.shape)"
   ],
   "id": "481ce57f2d093dc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mood features after leakage guard: (294616, 63)\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocessing (ColumnTransformer)\n",
    "\n",
    "Wir nutzen zwei Preprocessing-Varianten:\n",
    "\n",
    "### A) Für Tree-Modelle (XGBoost)\n",
    "- Numeric: **Median-Imputation**\n",
    "- Categorical: **Most-frequent-Imputation + OneHotEncoder**\n",
    "\n",
    "### B) Für lineare Modelle (z.B. SGD im Multi-Label Mood Task)\n",
    "- Numeric: **Median-Imputation + StandardScaler(with_mean=False)**\n",
    "- Categorical: **Most-frequent-Imputation + OneHotEncoder**\n",
    "- Scaling hilft linearen Modellen, stabiler zu trainieren.\n"
   ],
   "id": "37c43c50e091429a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:41:21.642726Z",
     "start_time": "2025-12-23T09:41:21.619599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def onehot_encoder_compat():\n",
    "    # Falls du unterschiedliche sklearn-Versionen hast, bleibt es robust:\n",
    "    return OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "def build_preprocessor_tree(X: pd.DataFrame) -> Tuple[ColumnTransformer, List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Preprocessing für XGBoost/Tree-Modelle:\n",
    "    - Numeric: Imputer\n",
    "    - Categorical: Imputer + OneHot\n",
    "    - Kein Scaling\n",
    "    \"\"\"\n",
    "    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "    categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", onehot_encoder_compat()),\n",
    "    ])\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, numeric_cols),\n",
    "            (\"cat\", cat_pipe, categorical_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "    return pre, numeric_cols, categorical_cols\n",
    "\n",
    "\n",
    "def build_preprocessor_linear(X: pd.DataFrame) -> Tuple[ColumnTransformer, List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Preprocessing für lineare Modelle (SGD/Ridge):\n",
    "    - Numeric: Imputer + Scaling\n",
    "    - Categorical: Imputer + OneHot\n",
    "    \"\"\"\n",
    "    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "    categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),  # wichtig wegen Sparse-Matrix\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", onehot_encoder_compat()),\n",
    "    ])\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, numeric_cols),\n",
    "            (\"cat\", cat_pipe, categorical_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "    return pre, numeric_cols, categorical_cols\n"
   ],
   "id": "86375c2c9c3e94be",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train: Track Popularity Regression (XGBoost)\n",
    "\n",
    "Ziel: Vorhersage der **Track-Popularität** (0–100).\n",
    "\n",
    "### Warum XGBoost?\n",
    "- Modelliert **nichtlineare Zusammenhänge** (wichtiger Vorteil gegenüber Ridge).\n",
    "- Funktioniert sehr gut auf tabellarischen Daten mit gemischten Features.\n",
    "- Kann mit sparsamen One-Hot-Features umgehen (über sklearn Pipeline).\n",
    "\n",
    "### Evaluation\n",
    "Wir reporten:\n",
    "- MAE\n",
    "- RMSE\n",
    "- R²\n",
    "\n"
   ],
   "id": "b2cb93c5fc8cab04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:43:01.477444Z",
     "start_time": "2025-12-23T09:41:21.661073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def sklearn_sanitize_df(X):\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        return X\n",
    "\n",
    "    X = X.copy()\n",
    "\n",
    "    # Convert NaT -> np.nan\n",
    "    X = X.replace({pd.NaT: np.nan})\n",
    "\n",
    "    for c in X.columns:\n",
    "        dt = X[c].dtype\n",
    "\n",
    "        # pandas string or categorical -> object + np.nan\n",
    "        if pd.api.types.is_string_dtype(dt) or isinstance(dt, pd.CategoricalDtype):\n",
    "            X[c] = X[c].astype(\"object\")\n",
    "            X[c] = X[c].where(pd.notna(X[c]), np.nan)\n",
    "\n",
    "        # pandas nullable boolean -> float (0/1/nan)\n",
    "        elif str(dt) == \"boolean\":\n",
    "            X[c] = X[c].astype(\"float64\")\n",
    "\n",
    "        # pandas nullable integer (Int64, Int32...) -> float (so missing -> np.nan)\n",
    "        elif str(dt).startswith(\"Int\"):\n",
    "            X[c] = X[c].astype(\"float64\")\n",
    "\n",
    "        # object columns might still contain pd.NA -> replace with np.nan\n",
    "        elif X[c].dtype == \"object\":\n",
    "            X[c] = X[c].where(pd.notna(X[c]), np.nan)\n",
    "\n",
    "    return X\n",
    "\n",
    "sanitize_tf = FunctionTransformer(sklearn_sanitize_df, feature_names_out=\"one-to-one\")\n",
    "\n",
    "\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_track_pop, y_track_pop_clean, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "pre_track, _, _ = build_preprocessor_tree(X_track_pop)\n",
    "\n",
    "xgb_track = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=1,\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe_track_pop = Pipeline(steps=[\n",
    "    (\"sanitize\", sanitize_tf),\n",
    "    (\"pre\", pre_track),\n",
    "    (\"model\", xgb_track),\n",
    "])\n",
    "\n",
    "pipe_track_pop.fit(Xtr, ytr)\n",
    "pred = pipe_track_pop.predict(Xte)\n",
    "\n",
    "track_pop_metrics = regression_report(yte, pred)\n",
    "dump(pipe_track_pop, PATHS.models_dir / \"03_track_popularity_pipeline_xgb.joblib\")\n"
   ],
   "id": "12474ea3a87cfd0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\models\\\\03_track_popularity_pipeline_xgb.joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Train: Hit Prediction (Binary Classification, XGBoost)\n",
    "\n",
    "Ziel: Vorhersage, ob ein Track ein **Hit** ist (`0/1`).\n",
    "\n",
    "### Warum XGBoost?\n",
    "- Lernt komplexe Regeln (nichtlinear)\n",
    "- Oft deutlich bessere PR-AUC/F1 bei “Hit”-ähnlichen Problemen\n",
    "\n",
    "### Zwei wichtige Tricks\n",
    "1. **Class Imbalance**: Wir setzen `scale_pos_weight`.\n",
    "2. **Threshold-Tuning**: Wir wählen den Threshold, der den F1-Score maximiert.\n",
    "\n"
   ],
   "id": "8cb546342ada5133"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:44:04.838866Z",
     "start_time": "2025-12-23T09:43:01.513508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Train/Test Split (stratifiziert, damit Klassenverteilung stabil bleibt)\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_track_hit, y_hit_clean,\n",
    "    test_size=0.2, random_state=RANDOM_SEED, stratify=y_hit_clean\n",
    ")\n",
    "\n",
    "# 2) Tree-Preprocessing (kein Scaling)\n",
    "pre_hit, _, _ = build_preprocessor_tree(X_track_hit)\n",
    "\n",
    "# 3) Class-Imbalance Gewicht (wichtig!)\n",
    "neg = int((ytr == 0).sum())\n",
    "pos = int((ytr == 1).sum())\n",
    "scale_pos_weight = neg / max(pos, 1)\n",
    "\n",
    "# 4) XGBoost Classifier\n",
    "xgb_hit = XGBClassifier(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=1,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",              # PR-AUC ist oft sinnvoller bei Imbalance\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 5) Pipeline\n",
    "pipe_hit = Pipeline(steps=[\n",
    "    (\"sanitize\", sanitize_tf),\n",
    "    (\"pre\", pre_hit),\n",
    "    (\"model\", xgb_hit),\n",
    "])\n",
    "\n",
    "# 6) Trainieren\n",
    "pipe_hit.fit(Xtr, ytr)\n",
    "\n",
    "# 7) Wahrscheinlichkeiten + Threshold-Tuning\n",
    "proba = pipe_hit.predict_proba(Xte)[:, 1]\n",
    "thr, thr_f1 = best_f1_threshold(yte, proba)\n",
    "\n",
    "hit_metrics = classification_report_binary(yte, proba, threshold=thr)\n",
    "hit_metrics[\"best_threshold\"] = thr\n",
    "hit_metrics[\"best_threshold_f1\"] = thr_f1\n",
    "\n",
    "# 8) Speichern (Name konsistent!)\n",
    "dump(pipe_hit, PATHS.models_dir / \"03_hit_pipeline_xgb.joblib\")\n",
    "\n",
    "hit_metrics\n"
   ],
   "id": "9fa9841b850b7687",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8441186758662217,\n",
       " 'pr_auc': 0.5505130587283013,\n",
       " 'f1': 0.5326656682890303,\n",
       " 'confusion_matrix': [[43247, 6105], [3881, 5691]],\n",
       " 'best_threshold': 0.6,\n",
       " 'best_threshold_f1': 0.5326656682890303}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train: Explicit Prediction (Binary Classification, XGBoost)\n",
    "\n",
    "Ziel: Vorhersage, ob ein Track als **explicit** markiert ist (`0/1`).\n",
    "\n",
    "### Warum XGBoost?\n",
    "- Sehr stark auf tabellarischen Daten\n",
    "- Gute Performance bei gemischten Features\n",
    "- Wir nutzen zusätzlich **Threshold-Tuning**, um F1 zu verbessern.\n",
    "\n"
   ],
   "id": "a75db18bc76b57c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:44:48.298171Z",
     "start_time": "2025-12-23T09:44:04.874850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pre_exp, _, _ = build_preprocessor_tree(X_track_explicit)\n",
    "\n",
    "xgb_explicit = XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe_explicit = Pipeline(steps=[\n",
    "    (\"sanitize\", sanitize_tf),\n",
    "    (\"pre\", pre_exp),\n",
    "    (\"model\", xgb_explicit),\n",
    "])\n",
    "\n",
    "pipe_explicit.fit(Xtr, ytr)  # keep your existing train/test split block for explicit\n",
    "proba = pipe_explicit.predict_proba(Xte)[:, 1]\n",
    "\n",
    "thr, thr_f1 = best_f1_threshold(yte, proba)\n",
    "explicit_metrics = classification_report_binary(yte, proba, threshold=thr)\n",
    "explicit_metrics[\"best_threshold\"] = thr\n",
    "explicit_metrics[\"best_threshold_f1\"] = thr_f1\n",
    "\n",
    "dump(pipe_explicit, PATHS.models_dir / \"03_explicit_pipeline_xgb.joblib\")\n",
    "\n"
   ],
   "id": "f3ad93484a89121",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\models\\\\03_explicit_pipeline_xgb.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Künstler-Clustering (Unsupervised)\n",
    "\n",
    "Ziel: Künstler in **Segmente/Cluster** einteilen (z.B. für Exploration, Empfehlungen, Marketing-Personas oder später als Feature).\n",
    "\n",
    "**Idee:** Kein Graph-Community-Detection (Louvain/Leiden), sondern **Feature-basiertes Clustering**.\n",
    "\n",
    "**Pipeline (kurz):**\n",
    "1) Artist-Features auswählen (Follower/Popularity/Katalog + Audio-Feature-Mittelwerte, optional Genre-Multi-Hot)\n",
    "2) Fehlwerte imputieren (Median)\n",
    "3) Skalieren (wichtig, weil Distanz-basiert)\n",
    "4) PCA (stabiler/schneller für KMeans)\n",
    "5) KMeans → `artist_df[\"cluster\"]`\n",
    "Optional: t-SNE nur als visuelle Diagnose auf einem Sample\n",
    "\n",
    "**Outputs:**\n",
    "- `artist_df[\"cluster\"]`\n",
    "- gespeicherte Artefakte: Preprocessing + PCA + KMeans (`03_artist_clustering.joblib`)\n",
    "- Dataset mit Clustern als Parquet\n"
   ],
   "id": "ad7e6a2a9d9bea91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:45:08.641815Z",
     "start_time": "2025-12-23T09:44:48.329235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Artist Clustering\n",
    "# =========================\n",
    "\n",
    "# 2) Artist-Level Features auswählen (nur sinnvolle numerische Features)\n",
    "ARTIST_NUM = [\n",
    "                 \"popularity\", \"followers\", \"log_followers\",\n",
    "                 \"n_tracks\", \"log_n_tracks\",\n",
    "                 \"track_pop_mean\", \"explicit_rate\",\n",
    "             ] + [c for c in artist_df.columns if c.startswith(\"mean_\")]  # z.B. mean_energy, mean_danceability, ...\n",
    "\n",
    "X_artist_base = artist_df[ARTIST_NUM].copy()\n",
    "\n",
    "# 3) Optional: Genre Multi-Hot anhängen (falls vorhanden)\n",
    "if \"artist_genre_mh\" in globals() and isinstance(artist_genre_mh, pd.DataFrame) and len(artist_genre_mh.columns) > 0:\n",
    "    X_artist = pd.concat(\n",
    "        [X_artist_base.reset_index(drop=True), artist_genre_mh.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "else:\n",
    "    X_artist = X_artist_base\n",
    "\n",
    "# 4) Nur numerische Spalten fürs Clustering behalten (KMeans braucht numeric)\n",
    "num_cols = [c for c in X_artist.columns if pd.api.types.is_numeric_dtype(X_artist[c])]\n",
    "X_num = X_artist[num_cols].copy()\n",
    "\n",
    "# 5) Preprocessing fürs Clustering: Impute + Scale\n",
    "#    (Skalierung ist wichtig, weil KMeans distanzbasiert arbeitet.)\n",
    "cluster_pre = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=True)),  # hier OK, weil wir eine dichte Matrix nutzen\n",
    "])\n",
    "\n",
    "X_scaled = cluster_pre.fit_transform(X_num)\n",
    "\n",
    "# 6) PCA: reduziert Dimensionalität → stabiler & schneller für KMeans\n",
    "pca_components = min(30, X_scaled.shape[1])  # max 30 oder weniger, wenn weniger Features existieren\n",
    "pca = PCA(n_components=pca_components, random_state=RANDOM_SEED)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 7) KMeans Clustering\n",
    "kmeans = kmeans_compat(n_clusters=K_CLUSTERS, random_state=RANDOM_SEED)\n",
    "artist_clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Cluster-Label ins artist_df schreiben\n",
    "artist_df[\"cluster\"] = artist_clusters.astype(int)\n",
    "\n",
    "# 8) Optional: t-SNE nur als Diagnose (auf Sample, weil teuer)\n",
    "SAMPLE_TSNE = min(TSNE_SAMPLE_MAX, len(artist_df))\n",
    "tsne_coords = None\n",
    "if SAMPLE_TSNE >= 500:  # erst ab sinnvoller Größe (kannst du anpassen)\n",
    "    sample_idx = np.random.choice(len(artist_df), size=SAMPLE_TSNE, replace=False)\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=30,\n",
    "        learning_rate=\"auto\",\n",
    "        init=\"pca\",\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    tsne_coords = tsne.fit_transform(X_pca[sample_idx])\n",
    "\n",
    "# 9) Kleiner Report fürs metrics_report.json (damit es später nicht crasht)\n",
    "artist_cluster_artifact = {\n",
    "    \"k\": int(K_CLUSTERS),\n",
    "    \"n_artists\": int(len(artist_df)),\n",
    "    \"n_features_used\": int(X_num.shape[1]),\n",
    "    \"pca_components\": int(pca_components),\n",
    "    \"pca_explained_variance_ratio_sum\": float(np.sum(pca.explained_variance_ratio_)),\n",
    "    \"tsne_sample_n\": int(SAMPLE_TSNE),\n",
    "}\n",
    "\n",
    "# 10) Artefakte speichern (für Notebook 4 / Wiederverwendung)\n",
    "cluster_bundle = {\n",
    "    \"cluster_pre\": cluster_pre,\n",
    "    \"pca\": pca,\n",
    "    \"kmeans\": kmeans,\n",
    "    \"numeric_columns_used\": num_cols,\n",
    "    \"k\": int(K_CLUSTERS),\n",
    "}\n",
    "\n",
    "dump(cluster_bundle, PATHS.models_dir / \"03_artist_clustering.joblib\")\n",
    "artist_df.to_parquet(PATHS.modeling_dir / \"artist_dataset_with_clusters.parquet\", index=False)\n",
    "\n",
    "artist_cluster_artifact\n"
   ],
   "id": "d5bd81e877435b70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 30,\n",
       " 'n_artists': 139608,\n",
       " 'n_features_used': 66,\n",
       " 'pca_components': 30,\n",
       " 'pca_explained_variance_ratio_sum': 0.770467701580219,\n",
       " 'tsne_sample_n': 4000}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train: Album Popularity Regression (XGBoost)\n",
    "\n",
    "Ziel: Vorhersage der **Album-Popularität** (0–100).\n",
    "\n",
    "### Warum XGBoost statt Ridge?\n",
    "- Nichtlineare Effekte (z.B. Release-Zeitpunkt, Track-Anzahl, Artist-Popularity) werden besser modelliert.\n",
    "- Meist bessere MAE/RMSE als lineare Modelle.\n",
    "\n"
   ],
   "id": "562f8a9d0237e8d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:45:37.184589Z",
     "start_time": "2025-12-23T09:45:08.651999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_album_pop, y_album_pop_clean, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "pre_album, _, _ = build_preprocessor_tree(X_album_pop)\n",
    "\n",
    "xgb_album = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=1,\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe_album_pop = Pipeline(steps=[\n",
    "    (\"sanitize\", sanitize_tf),\n",
    "    (\"pre\", pre_album),\n",
    "    (\"model\", xgb_album),\n",
    "])\n",
    "\n",
    "pipe_album_pop.fit(Xtr, ytr)\n",
    "pred = pipe_album_pop.predict(Xte)\n",
    "\n",
    "album_pop_metrics = regression_report(yte, pred)\n",
    "dump(pipe_album_pop, PATHS.models_dir / \"03_album_popularity_pipeline_xgb.joblib\")"
   ],
   "id": "29a8df113de59ed4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\models\\\\03_album_popularity_pipeline_xgb.joblib']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Train: Mood Tags (Multi-Label)\n",
    "\n",
    "Ziel: Mehrere Mood-Tags pro Track (z.B. happy, energetic, calm).\n",
    "\n",
    "### Modellwahl (skalierbar)\n",
    "Wir nutzen **One-vs-Rest** mit einem schnellen linearen Modell (SGDClassifier),\n",
    "weil Multi-Label bedeutet:\n",
    "- pro Label ein eigener Klassifikator\n",
    "- sehr gut skalierbar auf große, sparse Feature-Matrizen\n",
    "\n"
   ],
   "id": "fc1625152b6453b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:45:44.517509Z",
     "start_time": "2025-12-23T09:45:37.193911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "Xtr, Xte, Ytr, Yte = train_test_split(\n",
    "    X_track_mood, Y_mood_clean,\n",
    "    test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "pre_mood, _, _ = build_preprocessor_linear(X_track_mood)\n",
    "\n",
    "base_sgd = SGDClassifier(\n",
    "    loss=\"log_loss\",          # logistic\n",
    "    alpha=1e-4,               # regularization (tune later)\n",
    "    max_iter=2000,\n",
    "    tol=1e-3,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_SEED,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "mood_model = OneVsRestClassifier(base_sgd, n_jobs=-1)\n",
    "\n",
    "pipe_mood = Pipeline(steps=[\n",
    "    (\"sanitize\", sanitize_tf),\n",
    "    (\"pre\", pre_mood),\n",
    "    (\"model\", mood_model),\n",
    "])\n",
    "\n",
    "pipe_mood.fit(Xtr, Ytr)\n",
    "\n",
    "proba = pipe_mood.predict_proba(Xte)          # (n_samples, n_labels)\n",
    "pred  = (proba >= 0.5).astype(int)            # threshold can be tuned per-label\n",
    "\n",
    "mood_micro_f1 = float(f1_score(Yte, pred, average=\"micro\"))\n",
    "mood_macro_f1 = float(f1_score(Yte, pred, average=\"macro\"))\n",
    "per_label_f1  = {col: float(f1_score(Yte[col], pred[:, i])) for i, col in enumerate(Yte.columns)}\n",
    "\n",
    "mood_metrics = {\n",
    "    \"micro_f1\": mood_micro_f1,\n",
    "    \"macro_f1\": mood_macro_f1,\n",
    "    \"per_label_f1\": per_label_f1\n",
    "}\n",
    "\n",
    "dump(pipe_mood, PATHS.models_dir / \"03_mood_pipeline.joblib\")\n",
    "mood_metrics\n"
   ],
   "id": "49a439136b1ba12f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'micro_f1': 0.4154901638895729,\n",
       " 'macro_f1': 0.38365217246396127,\n",
       " 'per_label_f1': {'energetic': 0.4284363498828972,\n",
       "  'danceable': 0.2314473473313031,\n",
       "  'acoustic': 0.449276528625002,\n",
       "  'instrumental': 0.45004217467985586,\n",
       "  'happy': 0.23244849851388746,\n",
       "  'sad': 0.44405376896654314,\n",
       "  'chill': 0.44986053924824015}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:46:04.079321Z",
     "start_time": "2025-12-23T09:45:44.530058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ARTIST_NUM = [\n",
    "    \"popularity\", \"followers\", \"log_followers\",\n",
    "    \"n_tracks\", \"log_n_tracks\",\n",
    "    \"track_pop_mean\", \"explicit_rate\",\n",
    "] + [c for c in artist_df.columns if c.startswith(\"mean_\")]\n",
    "\n",
    "ARTIST_NUM = [c for c in ARTIST_NUM if c in artist_df.columns]\n",
    "X_artist_base = artist_df[ARTIST_NUM].copy()\n",
    "\n",
    "# Optional: add genre multihot (numeric features)\n",
    "X_artist = pd.concat([X_artist_base.reset_index(drop=True), artist_genre_mh.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Keep only numeric columns for clustering (KMeans requires numeric)\n",
    "num_cols = [c for c in X_artist.columns if pd.api.types.is_numeric_dtype(X_artist[c])]\n",
    "X_num = X_artist[num_cols].copy()\n",
    "\n",
    "cluster_pre = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=True)),\n",
    "])\n",
    "\n",
    "X_scaled = cluster_pre.fit_transform(X_num)\n",
    "\n",
    "# PCA: reduce dims to make clustering easier and more stable\n",
    "pca_components = min(30, X_scaled.shape[1])\n",
    "pca = PCA(n_components=pca_components, random_state=RANDOM_SEED)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# KMeans clusters\n",
    "kmeans = kmeans_compat(n_clusters=K_CLUSTERS, random_state=RANDOM_SEED)\n",
    "artist_clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "artist_df[\"cluster\"] = artist_clusters\n",
    "\n",
    "SAMPLE_TSNE = min(TSNE_SAMPLE_MAX, len(artist_df))\n",
    "sample_idx = np.random.choice(len(artist_df), size=SAMPLE_TSNE, replace=False)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=\"auto\", init=\"pca\", random_state=RANDOM_SEED)\n",
    "X_tsne = tsne.fit_transform(X_pca[sample_idx])\n",
    "\n",
    "artist_cluster_artifact = {\n",
    "    \"k\": int(K_CLUSTERS),\n",
    "    \"pca_components\": int(pca_components),\n",
    "    \"pca_explained_variance_ratio_sum\": float(np.sum(pca.explained_variance_ratio_)),\n",
    "    \"tsne_sample_n\": int(SAMPLE_TSNE),\n",
    "}\n",
    "\n",
    "# Save clustering artifacts for reuse (Notebook 4 or analysis)\n",
    "cluster_bundle = {\n",
    "    \"cluster_pre\": cluster_pre,\n",
    "    \"pca\": pca,\n",
    "    \"kmeans\": kmeans,\n",
    "    \"numeric_columns_used\": num_cols,\n",
    "    \"k\": int(K_CLUSTERS),\n",
    "}\n",
    "dump(cluster_bundle, PATHS.models_dir / \"03_artist_clustering.joblib\")\n",
    "artist_df.to_parquet(PATHS.modeling_dir / \"artist_dataset_with_clusters.parquet\", index=False)\n"
   ],
   "id": "9201fbc9a264459a",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## `feature_config.json` speichern\n",
    "\n",
    "An dieser Stelle exportieren wir die Datei **`feature_config.json`**.\n",
    "Sie dient als **Scoring-Vertrag** zwischen Notebook 3 (Training) und Notebook 4 (Batch-Scoring).\n",
    "\n",
    "### Warum diese Datei wichtig ist\n",
    "\n",
    "Beim späteren Scoring (z. B. Millionen Datensätze) müssen **exakt dieselben Regeln** wie beim Training angewendet werden.\n",
    "Die `feature_config.json` stellt **Reproduzierbarkeit und Konsistenz** sicher.\n",
    "\n",
    "### Inhalt der `feature_config.json`\n",
    "\n",
    "* **Feature-Listen**\n",
    "\n",
    "  * numerische Features\n",
    "  * kategoriale Features\n",
    "  * Multi-Hot-Genre-Features\n",
    "\n",
    "* **Genre-Encoding**\n",
    "\n",
    "  * feste `top_genres`-Liste (gleiche Reihenfolge, gleiche Spalten)\n",
    "\n",
    "* **Mood-Tags**\n",
    "\n",
    "  * Schwellenwerte (z. B. Quantile für `valence`, `energy`)\n",
    "  * Logik (`gt` / `lt`) und Tag-Namen\n",
    "\n",
    "* **Hit-Label**\n",
    "\n",
    "  * Parameter zur Hit-Definition (z. B. Perzentil)\n",
    "  * sorgt für konsistente Zielerstellung\n",
    "\n",
    "* **Metadaten (optional)**\n",
    "\n",
    "  * Zeitstempel, Dataset-Version, Run-Infos\n"
   ],
   "id": "196de044d6f02d7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:46:04.095148Z",
     "start_time": "2025-12-23T09:46:04.089113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_config = {\n",
    "    \"run_meta\": RUN_META,\n",
    "    \"top_genres\": top_genres,\n",
    "    \"mood_thresholds\": {str(k): v for k, v in mood_thresholds.items()},  # keys must be JSON-serializable\n",
    "    \"mood_tags\": MOOD_TAGS,\n",
    "    \"track_features\": {\n",
    "        \"numeric\": TRACK_NUMERIC,\n",
    "        \"categorical\": TRACK_CATEGORICAL,\n",
    "        \"genre_multi_hot_cols\": list(track_genre_mh.columns),\n",
    "    },\n",
    "    \"album_features\": {\n",
    "        \"numeric\": ALBUM_NUMERIC,\n",
    "        \"categorical\": ALBUM_CATEGORICAL,\n",
    "        \"genre_multi_hot_cols\": list(album_genre_mh.columns),\n",
    "    },\n",
    "    \"artist_features\": {\n",
    "        \"numeric_used_for_clustering\": num_cols,\n",
    "        \"genre_multi_hot_cols\": list(artist_genre_mh.columns),\n",
    "        \"kmeans_k\": int(K_CLUSTERS),\n",
    "    },\n",
    "    \"targets\": {\n",
    "        \"hit_percentile_within_year\": float(HIT_PERCENTILE),\n",
    "        \"hit_fallback_popularity_threshold\": int(HIT_FALLBACK_POP_THRESHOLD),\n",
    "    }\n",
    "}\n",
    "\n",
    "(PATHS.models_dir / \"feature_config.json\").write_text(json.dumps(feature_config, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved feature_config.json\")\n"
   ],
   "id": "fe4f5c2e9754f8d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature_config.json\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Write Reports (JSON)\n",
    "\n",
    "In this step we persist the most important outputs of Notebook 3 as **machine-readable reports**.\n",
    "\n",
    "### Why we write JSON reports\n",
    "Saving metrics only as printed notebook output is not reproducible.\n",
    "A JSON report allows you to:\n",
    "\n",
    "- compare experiments across runs (baseline vs tuned models)\n",
    "- track progress over time (model improvements)\n",
    "- integrate results into dashboards or CI pipelines\n",
    "- make Notebook 4 and later steps auditable\n",
    "\n",
    "### What we store\n",
    "The report typically includes:\n",
    "\n",
    "- **Model metrics**\n",
    "  - track popularity regression (MAE / RMSE / R²)\n",
    "  - album popularity regression (MAE / RMSE / R²)\n",
    "  - hit prediction (ROC-AUC / PR-AUC / F1 / precision / recall)\n",
    "  - explicit prediction (ROC-AUC / PR-AUC / F1 / precision / recall)\n",
    "  - mood multi-label metrics (micro F1 / macro F1 / per-label F1)\n",
    "  - artist clustering artifacts (e.g., `k`, PCA variance explained)\n",
    "\n",
    "- **Dataset shapes**\n",
    "  - shapes of the prepared datasets (`track_df`, `album_df`, `artist_df`)\n",
    "  - shapes of the feature matrices used for training\n",
    "  - helps detect accidental row drops or mismatched joins later\n",
    "\n",
    "### Output location\n",
    "The JSON report is written into the `reports/` directory (e.g. `metrics_report.json`).\n",
    "This becomes the single source of truth for model performance for this run.\n"
   ],
   "id": "8426d9b6ec2fe819"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T09:46:04.110164Z",
     "start_time": "2025-12-23T09:46:04.103602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reports = {\n",
    "    \"track_popularity_regression\": track_pop_metrics,\n",
    "    \"album_popularity_regression\": album_pop_metrics,\n",
    "    \"hit_prediction\": hit_metrics,\n",
    "    \"explicit_prediction\": explicit_metrics,\n",
    "    \"mood_multilabel\": mood_metrics,\n",
    "    \"artist_clustering\": artist_cluster_artifact,\n",
    "    \"dataset_shapes\": {\n",
    "        \"track_df\": [int(track_df.shape[0]), int(track_df.shape[1])],\n",
    "        \"album_df\": [int(album_df.shape[0]), int(album_df.shape[1])],\n",
    "        \"artist_df\": [int(artist_df.shape[0]), int(artist_df.shape[1])],\n",
    "        \"X_track_pop\": [int(X_track_pop.shape[0]), int(X_track_pop.shape[1])],\n",
    "        \"X_album_pop\": [int(X_album_pop.shape[0]), int(X_album_pop.shape[1])],\n",
    "    },\n",
    "}\n",
    "\n",
    "(PATHS.reports_dir / \"metrics_report_xgb.json\").write_text(json.dumps(reports, indent=2), encoding=\"utf-8\")\n",
    "print(\"Wrote metrics report:\", PATHS.reports_dir / \"metrics_report_xgb.json\")\n"
   ],
   "id": "c5bddb5838d1722a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metrics report: ..\\data\\reports\\03_target_and_features\\metrics_report_xgb.json\n"
     ]
    }
   ],
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
