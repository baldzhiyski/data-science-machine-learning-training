{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 06 — Fine Tuning und Robustheit\n",
    "\n",
    "## Ziel\n",
    "Dieses Notebook beschreibt den Prozess der Feinabstimmung unseres Modells und die Bewertung seiner Robustheit gegenüber verschiedenen Störungen in den Eingabedaten."
   ],
   "id": "21d6dd5bf577884d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports und Setup",
   "id": "9949ee7d53da317e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import utils.paths as paths\n",
    "from utils.data_loader import load_all\n",
    "from utils.reporting import ensure_dirs, save_joblib, save_json\n",
    "from utils.tasks.success_pct import SuccessPctTrainer\n",
    "\n",
    "import utils.tasks.success_residual as success_residual\n",
    "import utils.tasks.success_pct as success_pct\n",
    "import utils.tasks.hit as hit\n",
    "import utils.tasks.moods as moods\n",
    "import utils.tasks.ranker as ranker\n",
    "import utils.tasks.artist_trajectory as artist_trajectory\n",
    "import utils.tasks.artist_clustering as artist_clustering\n",
    "import utils.tasks.track_similarity as track_similarity\n",
    "\n",
    "# reload modules\n",
    "importlib.reload(success_pct)\n",
    "importlib.reload(success_residual)\n",
    "importlib.reload(hit)\n",
    "importlib.reload(moods)\n",
    "importlib.reload(ranker)\n",
    "importlib.reload(artist_trajectory)\n",
    "importlib.reload(artist_clustering)\n",
    "importlib.reload(track_similarity)\n",
    "\n",
    "# use classes from the module (always up to date)\n",
    "SuccessPctTrainer = success_pct.SuccessPctTrainer\n",
    "SuccessResidualTrainer = success_residual.SuccessResidualTrainer\n",
    "HitTrainer = hit.HitTrainer\n",
    "MoodTrainer = moods.MoodTrainer\n",
    "RankerTrainer = ranker.RankerTrainer\n",
    "ArtistTrajectoryTrainer = artist_trajectory.ArtistTrajectoryTrainer\n",
    "ArtistClusteringRunner = artist_clustering.ArtistClusteringRunner\n",
    "TrackSimilarityRunner = track_similarity.TrackSimilarityRunner\n",
    "\n",
    "from utils.datasets import  (\n",
    "    build_success_pct_dataset,\n",
    "    build_success_residual_dataset,\n",
    "    build_hit_dataset,\n",
    "    build_mood_dataset,\n",
    ")\n",
    "\n",
    "from utils.config import RANDOM_SEED, ALLOW_LEAKY_FEATURES\n",
    "\n",
    "importlib.reload(paths)\n",
    "\n",
    "SAMPLE_NAME = paths.load_sample_name()\n",
    "PATHS = paths.make_paths(SAMPLE_NAME)\n",
    "paths.ensure_dirs(PATHS)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "9cbfe93ed5fa3830"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = load_all(PATHS.input_targets_path)\n",
    "\n",
    "ds_pct  = build_success_pct_dataset(data.X_track, data.track_df, data.y_success_pct)\n",
    "ds_res  = build_success_residual_dataset(data.X_track, data.track_df, data.y_success_residual)\n",
    "ds_hit  = build_hit_dataset(data.X_track, data.track_df, data.y_hit)\n",
    "ds_mood = build_mood_dataset(data.X_track, data.track_df, data.Y_mood)\n",
    "\n",
    "ap = data.artist_panel.sort_values(\"release_month_ts\").reset_index(drop=True)\n",
    "\n",
    "y_artist_growth = ap[\"y_growth\"].astype(float)\n",
    "y_artist_breakout = ap[\"y_breakout\"].astype(int)\n",
    "\n",
    "X_artist_panel = ap.select_dtypes(include=[\"number\", \"bool\"]).drop(\n",
    "    columns=[\"y_growth\", \"y_breakout\", \"release_month_ts\", \"artist_id\"],\n",
    "    errors=\"ignore\"\n",
    ").fillna(0)\n",
    "\n"
   ],
   "id": "9e889c3bd7492db6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Success Percentile innerhalb der Kohorte (Regression)\n",
    "\n",
    "Ziel: Vorhersage der relativen Erfolgsposition eines Tracks innerhalb seiner Release-Kohorte (0–100).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **MAE auf dem Validierungsset minimieren**, da die Skala interpretierbar ist (Punkte im Perzentilraum).\n",
    "\n",
    "Hinweis:\n",
    "- Wir nutzen einen **kohortenbasierten Zeitsplit**, um Leakage in die Zukunft zu vermeiden.\n",
    "- Optional kann XGBoost auf **GPU (CUDA)** laufen (`device=\"cuda\"`).\n"
   ],
   "id": "7b2076a62a505d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pct_trainer = SuccessPctTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_pct = pct_trainer.tune(\n",
    "    ds_pct,\n",
    "    n_trials=40,\n",
    "    device=\"gpu\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_pct"
   ],
   "id": "eb2a1f49d5fb07f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Success Residual innerhalb der Kohorte (Regression)\n",
    "\n",
    "Ziel: Modellierung von **Über- oder Unterperformance** relativ zur Kohorte (Residual statt absoluter Erfolg).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **MAE auf dem Validierungsset minimieren** (robust, gut interpretierbar).\n",
    "\n",
    "Hinweis:\n",
    "- Residual-Targets sind oft verrauscht → Regularisierung ist besonders wichtig.\n",
    "- Kohortenbasierter Zeitsplit verhindert ungewollte Zukunftsinformation.\n"
   ],
   "id": "9665226b3737ea6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "res_trainer = SuccessResidualTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_res = res_trainer.tune(\n",
    "    ds_res,\n",
    "    n_trials=50,\n",
    "    device=\"cuda\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_res\n",
    "\n"
   ],
   "id": "9c5a8bd785f37cbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Hit Prediction (Binary Classification)\n",
    "\n",
    "Ziel: Vorhersage, ob ein Track als „Hit“ gilt.\n",
    "\n",
    "Optimierungsziel:\n",
    "- **PR-AUC auf dem Validierungsset maximieren**\n",
    "  (bei unausgeglichenen Klassen oft sinnvoller als ROC-AUC).\n",
    "\n",
    "Zusatz:\n",
    "- Der finale **Threshold** (für F1) wird später auf der Validierung optimiert (wie im Training-Notebook).\n",
    "- GPU ist möglich (XGBoost).\n"
   ],
   "id": "56090ac32e0a91f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hit_trainer = HitTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_hit = hit_trainer.tune(\n",
    "    ds_hit,\n",
    "    n_trials=60,\n",
    "    device=\"cuda\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_hit\n"
   ],
   "id": "e3f2417fa58b5276",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Mood Prediction (Multi-Label)\n",
    "\n",
    "Ziel: Mehrere Mood-Labels pro Track (z.B. happy, sad, chill …).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **Micro-F1 auf dem Validierungsset maximieren**\n",
    "  (gute Standardmetrik bei Multi-Label, weil sie alle Entscheidungen gemeinsam bewertet).\n",
    "\n",
    "Hinweis:\n",
    "- Viele sklearn-Modelle laufen CPU-basiert; GPU ist hier meistens nicht relevant.\n",
    "- Thresholds können später pro Label separat optimiert werden.\n"
   ],
   "id": "bcc19aec79efed2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mood_trainer = MoodTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_mood = mood_trainer.tune(\n",
    "    ds_mood,\n",
    "    n_trials=30,\n",
    ")\n",
    "\n",
    "best_mood\n"
   ],
   "id": "89547a8ae21dd7fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Ranker (Learning-to-Rank)\n",
    "\n",
    "Ziel: Tracks innerhalb einer Kohorte sinnvoll zu ranken (Top-K Qualität).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **Mean NDCG@10 auf dem Validierungsset maximieren**.\n",
    "\n",
    "Wichtig:\n",
    "- Ranking benötigt eine saubere Gruppierung (z.B. pro `cohort_ym`).\n",
    "- GPU ist möglich (XGBRanker).\n"
   ],
   "id": "b8a79c410503407a"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "rank_trainer = RankerTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_rank = rank_trainer.tune(\n",
    "    ds_pct,        # typischerweise nutzt der Ranker das gleiche X, aber anderes Training/Grouping\n",
    "    n_trials=30,\n",
    "    device=\"cuda\", # oder \"cpu\"\n",
    "    k=10\n",
    ")\n",
    "\n",
    "best_rank\n"
   ],
   "id": "2537c64a6333344",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Artist Trajectory (Growth & Breakout)\n",
    "\n",
    "Ziel: Künstlerentwicklung über Zeit modellieren.\n",
    "\n",
    "Teilaufgaben:\n",
    "- **Growth (Regression):** log1p-transformiertes Wachstum → **MAE minimieren**\n",
    "- **Breakout (Binary):** Breakout-Event → **PR-AUC maximieren**\n",
    "\n",
    "Hinweis:\n",
    "- Zeitliche Sortierung ist Pflicht, damit der Split korrekt ist.\n",
    "- GPU ist möglich (XGBoost).\n"
   ],
   "id": "26f997d24f2a85a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "artist_trainer = ArtistTrajectoryTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_artist = artist_trainer.tune(\n",
    "    data.artist_panel,\n",
    "    n_trials=30,\n",
    "    device=\"cuda\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_artist\n"
   ],
   "id": "2fdee917428c672f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Unsupervised Tuning: Artist Clustering (KMeans)\n",
    "\n",
    "In diesem Schritt optimieren wir das Clustering **ohne Ground Truth**.\n",
    "Dafür testen wir verschiedene Parameter (z.B. `k` und PCA-Dimensionen) auf einem **Sample**, um die Laufzeit gering zu halten.\n",
    "\n",
    "**Bewertung (Heuristiken):**\n",
    "- **Silhouette Score** (höher = besser getrennte Cluster)\n",
    "- **Davies–Bouldin Index** (niedriger = kompakter / besser)\n",
    "\n",
    "Anschließend trainieren wir das beste Setup auf dem vollständigen Datensatz und erzeugen optional eine 2D-PCA-Visualisierung.\n"
   ],
   "id": "cfb7277b1f5dd787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RNG = np.random.RandomState(RANDOM_SEED)\n",
    "\n",
    "# Sample Artists für schnellere Evaluierung\n",
    "sample_n = 8000\n",
    "idx = RNG.choice(len(data.artist_df), size=sample_n, replace=False)\n",
    "artist_sample = data.artist_df.iloc[idx].copy()\n",
    "\n",
    "def eval_clustering(k, pca_dim=16, scale=True):\n",
    "    runner = ArtistClusteringRunner(k=k, seed=RANDOM_SEED, scale=scale, pca_dim=pca_dim)\n",
    "    models, artifact, extra = runner.run(artist_sample)\n",
    "\n",
    "    X_used = extra[\"X_used\"]\n",
    "    labels = extra[\"labels\"]\n",
    "\n",
    "    sil = silhouette_score(X_used, labels)\n",
    "    db = davies_bouldin_score(X_used, labels)\n",
    "\n",
    "    return {\n",
    "        \"k\": k,\n",
    "        \"pca_dim\": pca_dim,\n",
    "        \"scale\": scale,\n",
    "        \"silhouette\": float(sil),\n",
    "        \"davies_bouldin\": float(db),\n",
    "        \"artifact\": artifact,\n",
    "    }\n",
    "\n",
    "candidates = []\n",
    "for k in [10, 15, 20, 25, 30, 35, 40, 50]:\n",
    "    for pca_dim in [8, 12, 16]:\n",
    "        candidates.append(eval_clustering(k=k, pca_dim=pca_dim, scale=True))\n",
    "\n",
    "df_c = pd.DataFrame([{k: v for k, v in c.items() if k != \"artifact\"} for c in candidates])\n",
    "df_c.sort_values([\"silhouette\", \"davies_bouldin\"], ascending=[False, True]).head(10)\n"
   ],
   "id": "3f51f1117b08dac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_row = df_c.sort_values([\"silhouette\", \"davies_bouldin\"], ascending=[False, True]).iloc[0]\n",
    "best_cluster_cfg = best_row.to_dict()\n",
    "best_cluster_cfg\n"
   ],
   "id": "8e339745ff7836c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_runner = ArtistClusteringRunner(\n",
    "    k=int(best_cluster_cfg[\"k\"]),\n",
    "    seed=RANDOM_SEED,\n",
    "    scale=bool(best_cluster_cfg[\"scale\"]),\n",
    "    pca_dim=int(best_cluster_cfg[\"pca_dim\"]),\n",
    ")\n",
    "cluster_models, cluster_artifact, cluster_extra = cluster_runner.run(data.artist_df)\n",
    "\n",
    "# optional plot on sample\n",
    "cluster_runner.plot_pca2(cluster_extra[\"X_used\"], cluster_extra[\"labels\"])\n"
   ],
   "id": "8d873da90b286227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Embeddings & Track Similarity: Plausibilitäts-Checks\n",
    "\n",
    "Track-Similarity ist in der Praxis oft **qualitativ** zu bewerten (klingen/fühlen sich die Nachbarn ähnlich an?).\n",
    "Hier führen wir daher einen stabilen Check durch:\n",
    "\n",
    "- Embedding einmal fitten\n",
    "- Mehrere **gültige Track-Keys** auswählen\n",
    "- Für jeden Key die Top-K ähnlichsten Tracks abrufen\n",
    "\n",
    "Ziel: Sicherstellen, dass die Pipeline funktioniert, die Keys korrekt gematcht werden und die Ergebnisse plausibel sind.\n"
   ],
   "id": "c3fb147c875a2603"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sim_runner = TrackSimilarityRunner()\n",
    "sim_models, sim_artifact = sim_runner.fit(data.track_df)\n",
    "\n",
    "# choose valid keys correctly (avoid the '0' string issue)\n",
    "track_keys = data.track_df.index.to_numpy()\n",
    "\n",
    "RNG = np.random.RandomState(RANDOM_SEED)\n",
    "example_keys = RNG.choice(track_keys, size=5, replace=False)\n",
    "\n",
    "examples = {}\n",
    "for key in example_keys:\n",
    "    examples[str(key)] = sim_runner.get_similar(\n",
    "        track_key=key,\n",
    "        track_index=data.track_df.index,\n",
    "        embeddings=sim_models[\"embeddings\"],\n",
    "        top_k=10\n",
    "    )\n",
    "\n",
    "examples\n"
   ],
   "id": "a29b6287716cf5ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Finalisierung: Best-Modelle retrainen & Artefakte speichern\n",
    "\n",
    "Jetzt retrainen wir jedes Modell mit den **besten gefundenen Hyperparametern** und speichern:\n",
    "\n",
    "- Modelle nach `PATHS.tuned_models_dir`\n",
    "- Tuning-Report (Scores + Parameter + Artefakte) nach `PATHS.reports_dir_tuned`\n",
    "\n",
    "Damit ist die Tuning-Runde reproduzierbar und die Ergebnisse sind sauber versioniert.\n"
   ],
   "id": "72274e452a264dec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tuned_report = {}\n",
    "# success_pct\n",
    "pct_model, pct_metrics = pct_trainer.fit_eval(ds_pct, params=best_pct[\"best_params\"])\n",
    "save_joblib({\"model\": pct_model, \"best_params\": best_pct}, paths.tuned_models_dir / \"success_pct_tuned.joblib\")\n",
    "tuned_report[\"success_pct\"] = {\"best\": best_pct, \"metrics\": pct_metrics}\n",
    "\n",
    "# success_residual\n",
    "res_model, res_metrics = res_trainer.fit_eval(ds_res, params=best_res[\"best_params\"])\n",
    "save_joblib({\"model\": res_model, \"best_params\": best_res}, paths.tuned_models_dir / \"success_residual_tuned.joblib\")\n",
    "tuned_report[\"success_residual\"] = {\"best\": best_res, \"metrics\": res_metrics}\n",
    "\n",
    "# hit\n",
    "hit_model, hit_metrics, hit_thr = hit_trainer.fit_eval(ds_hit, params=best_hit[\"best_params\"])\n",
    "save_joblib({\"model\": hit_model, \"threshold\": hit_thr, \"best_params\": best_hit}, paths.tuned_models_dir / \"hit_tuned.joblib\")\n",
    "tuned_report[\"hit\"] = {\"best\": best_hit, \"metrics\": hit_metrics}\n",
    "\n",
    "# mood (optional)\n",
    "if best_mood is not None:\n",
    "    mood_model, mood_metrics, mood_thresholds = mood_trainer.fit_eval(ds_mood, params=best_mood[\"best_params\"])\n",
    "    save_joblib({\"model\": mood_model, \"thresholds\": mood_thresholds, \"best_params\": best_mood}, paths.tuned_models_dir / \"mood_tuned.joblib\")\n",
    "    tuned_report[\"mood\"] = {\"best\": best_mood, \"metrics\": mood_metrics}\n",
    "\n",
    "# ranker (optional)\n",
    "if \"best_rank\" in globals() and best_rank is not None:\n",
    "    rank_model, rank_metrics = rank_trainer.fit_eval(ds_pct, params=best_rank[\"best_params\"])\n",
    "    save_joblib({\"model\": rank_model, \"best_params\": best_rank}, paths.tuned_models_dir / \"ranker_tuned.joblib\")\n",
    "    tuned_report[\"ranker\"] = {\"best\": best_rank, \"metrics\": rank_metrics}\n",
    "\n",
    "# artist clustering (save fitted full model)\n",
    "save_joblib({\"models\": cluster_models, \"artifact\": cluster_artifact, \"best_cfg\": best_cluster_cfg},\n",
    "            paths.tuned_models_dir / \"artist_clustering_tuned.joblib\")\n",
    "tuned_report[\"artist_clustering\"] = {\"best_cfg\": best_cluster_cfg, \"artifact\": cluster_artifact}\n",
    "\n",
    "# track similarity (save embedding)\n",
    "save_joblib({\"models\": sim_models, \"artifact\": sim_artifact}, paths.tuned_models_dir / \"track_similarity.joblib\")\n",
    "tuned_report[\"track_similarity\"] = sim_artifact\n",
    "\n",
    "# final tuned report json\n",
    "tuned_report[\"run_config\"] = {\"seed\": RANDOM_SEED, \"allow_leaky_features\": ALLOW_LEAKY_FEATURES}\n",
    "save_json(tuned_report, paths.reports_dir_tuned / \"tuned_metrics_report.json\")\n",
    "\n",
    "tuned_report.keys()\n"
   ],
   "id": "c07598055e555079",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
