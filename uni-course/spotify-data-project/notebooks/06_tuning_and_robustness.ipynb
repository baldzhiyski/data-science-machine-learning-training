{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 06 — Fine Tuning und Robustheit\n",
    "\n",
    "## Ziel\n",
    "Dieses Notebook beschreibt den Prozess der Feinabstimmung unseres Modells und die Bewertung seiner Robustheit gegenüber verschiedenen Störungen in den Eingabedaten."
   ],
   "id": "21d6dd5bf577884d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports und Setup",
   "id": "9949ee7d53da317e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T07:34:20.808657Z",
     "start_time": "2026-01-18T07:34:10.279363Z"
    }
   },
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "import utils.paths as paths\n",
    "from utils.data_loader import load_all\n",
    "from utils.reporting import ensure_dirs, save_joblib, save_json\n",
    "from utils.config import RANDOM_SEED, ALLOW_LEAKY_FEATURES\n",
    "\n",
    "# Import modules (NOT classes) so reload works\n",
    "import utils.tasks.success_pct as success_pct\n",
    "import utils.tasks.success_residual as success_residual\n",
    "import utils.tasks.hit as hit\n",
    "import utils.tasks.moods as moods\n",
    "import utils.tasks.ranker as ranker\n",
    "import utils.tasks.artist_trajectory as artist_trajectory\n",
    "import utils.tasks.artist_clustering as artist_clustering\n",
    "import utils.tasks.track_similarity as track_similarity\n",
    "\n",
    "# Reload modules\n",
    "importlib.reload(success_pct)\n",
    "importlib.reload(success_residual)\n",
    "importlib.reload(hit)\n",
    "importlib.reload(moods)\n",
    "importlib.reload(ranker)\n",
    "importlib.reload(artist_trajectory)\n",
    "importlib.reload(artist_clustering)\n",
    "importlib.reload(track_similarity)\n",
    "\n",
    "# Keep references to CLASSES (optional)\n",
    "SuccessPctTrainer = success_pct.SuccessPctTrainer\n",
    "SuccessResidualTrainer = success_residual.SuccessResidualTrainer\n",
    "HitTrainer = hit.HitTrainer\n",
    "MoodTrainer = moods.MoodTrainer\n",
    "RankerTrainer = ranker.RankerTrainer\n",
    "ArtistTrajectoryTrainer = artist_trajectory.ArtistTrajectoryTrainer\n",
    "ArtistClusteringRunner = artist_clustering.ArtistClusteringRunner\n",
    "TrackSimilarityRunner = track_similarity.TrackSimilarityRunner\n",
    "\n",
    "from utils.datasets import (\n",
    "    build_success_pct_dataset,\n",
    "    build_success_residual_dataset,\n",
    "    build_hit_dataset,\n",
    "    build_mood_dataset,\n",
    ")\n",
    "\n",
    "# Reload paths if you need\n",
    "importlib.reload(paths)\n",
    "\n",
    "SAMPLE_NAME = paths.load_sample_name()\n",
    "PATHS = paths.make_paths(SAMPLE_NAME)\n",
    "paths.ensure_dirs(PATHS)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "9cbfe93ed5fa3830"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T07:34:28.355749Z",
     "start_time": "2026-01-18T07:34:20.834386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_all(PATHS.input_targets_path)\n",
    "\n",
    "ds_pct  = build_success_pct_dataset(data.X_track, data.track_df, data.y_success_pct)\n",
    "ds_res  = build_success_residual_dataset(data.X_track, data.track_df, data.y_success_residual)\n",
    "ds_hit  = build_hit_dataset(data.X_track, data.track_df, data.y_hit)\n",
    "ds_mood = build_mood_dataset(data.X_track, data.track_df, data.Y_mood)\n",
    "\n",
    "ap = data.artist_panel.sort_values(\"release_month_ts\").reset_index(drop=True)\n",
    "\n",
    "y_artist_growth = ap[\"y_growth\"].astype(float)\n",
    "y_artist_breakout = ap[\"y_breakout\"].astype(int)\n",
    "\n",
    "X_artist_panel = ap.select_dtypes(include=[\"number\", \"bool\"]).drop(\n",
    "    columns=[\"y_growth\", \"y_breakout\", \"release_month_ts\", \"artist_id\"],\n",
    "    errors=\"ignore\"\n",
    ").fillna(0)\n",
    "\n"
   ],
   "id": "9e889c3bd7492db6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Success Percentile innerhalb der Kohorte (Regression)\n",
    "\n",
    "Ziel: Vorhersage der relativen Erfolgsposition eines Tracks innerhalb seiner Release-Kohorte (0–100).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **MAE auf dem Validierungsset minimieren**, da die Skala interpretierbar ist (Punkte im Perzentilraum).\n",
    "\n",
    "Hinweis:\n",
    "- Wir nutzen einen **kohortenbasierten Zeitsplit**, um Leakage in die Zukunft zu vermeiden.\n",
    "- Optional kann XGBoost auf **GPU (CUDA)** laufen (`device=\"cuda\"`).\n"
   ],
   "id": "7b2076a62a505d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T08:13:28.302970Z",
     "start_time": "2026-01-18T07:34:28.937702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pct_trainer = SuccessPctTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_pct = pct_trainer.tune(\n",
    "    ds_pct,\n",
    "    n_trials=20,\n",
    "    device=\"gpu\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_pct"
   ],
   "id": "eb2a1f49d5fb07f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 08:34:29,022] A new study created in memory with name: no-name-453d0d56-7d50-46a4-9736-dffb0dbce36a\n",
      "C:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [08:34:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2026-01-18 08:34:58,434] Trial 0 finished with value: 20.855885981803535 and parameters: {'learning_rate': 0.07486048964184525, 'max_depth': 7, 'min_child_weight': 14.509167238588269, 'subsample': 0.8268761771357369, 'colsample_bytree': 0.8071046804455633, 'reg_lambda': 2.0393478476133713, 'reg_alpha': 0.9769416031451502, 'gamma': 1.1607552812643425, 'max_leaves': 214}. Best is trial 0 with value: 20.855885981803535.\n",
      "[I 2026-01-18 08:35:59,861] Trial 1 finished with value: 20.87308026712315 and parameters: {'learning_rate': 0.066134854614144, 'max_depth': 4, 'min_child_weight': 12.26732228692098, 'subsample': 0.7846616327430445, 'colsample_bytree': 0.7512065242499492, 'reg_lambda': 1.4421184266591993, 'reg_alpha': 0.6627464968514654, 'gamma': 1.5320956022475194, 'max_leaves': 180}. Best is trial 0 with value: 20.855885981803535.\n",
      "[I 2026-01-18 08:37:35,220] Trial 2 finished with value: 20.902904619605888 and parameters: {'learning_rate': 0.027851178769815584, 'max_depth': 5, 'min_child_weight': 26.015471091094188, 'subsample': 0.8433596892282933, 'colsample_bytree': 0.7902607045263331, 'reg_lambda': 36.256257605042485, 'reg_alpha': 0.10647374723237209, 'gamma': 1.8523987896866372, 'max_leaves': 241}. Best is trial 0 with value: 20.855885981803535.\n",
      "[I 2026-01-18 08:39:52,053] Trial 3 finished with value: 20.878662116607014 and parameters: {'learning_rate': 0.021834764063233304, 'max_depth': 5, 'min_child_weight': 6.697440966271384, 'subsample': 0.74099912030676, 'colsample_bytree': 0.895585078784744, 'reg_lambda': 34.20894114256263, 'reg_alpha': 0.000838711823490547, 'gamma': 0.8070893901937928, 'max_leaves': 50}. Best is trial 0 with value: 20.855885981803535.\n",
      "[I 2026-01-18 08:42:02,747] Trial 4 finished with value: 20.912473383297648 and parameters: {'learning_rate': 0.010066878883305565, 'max_depth': 7, 'min_child_weight': 39.40256074635199, 'subsample': 0.8019141787825864, 'colsample_bytree': 0.6748134024830003, 'reg_lambda': 2.9147820207626154, 'reg_alpha': 0.34322587332062293, 'gamma': 1.1677369177295558, 'max_leaves': 234}. Best is trial 0 with value: 20.855885981803535.\n",
      "[I 2026-01-18 08:43:41,262] Trial 5 finished with value: 20.851165521481814 and parameters: {'learning_rate': 0.047753719719598714, 'max_depth': 4, 'min_child_weight': 38.512085514035, 'subsample': 0.7949233637066072, 'colsample_bytree': 0.7075748410887535, 'reg_lambda': 9.64915254274076, 'reg_alpha': 0.00029929499878725914, 'gamma': 0.5047018096678477, 'max_leaves': 21}. Best is trial 5 with value: 20.851165521481814.\n",
      "[I 2026-01-18 08:44:22,584] Trial 6 finished with value: 20.87358736186417 and parameters: {'learning_rate': 0.05432379886624378, 'max_depth': 7, 'min_child_weight': 37.240490276768575, 'subsample': 0.8568981553132707, 'colsample_bytree': 0.8443244665760318, 'reg_lambda': 1.6703258371933651, 'reg_alpha': 0.16781267092167276, 'gamma': 1.7746857321680412, 'max_leaves': 197}. Best is trial 5 with value: 20.851165521481814.\n",
      "[I 2026-01-18 08:50:33,961] Trial 7 finished with value: 20.928954418268134 and parameters: {'learning_rate': 0.018992376913457246, 'max_depth': 3, 'min_child_weight': 20.233166094049956, 'subsample': 0.8585087759931488, 'colsample_bytree': 0.8922059352922657, 'reg_lambda': 5.984949616152582, 'reg_alpha': 0.0007629028519653544, 'gamma': 0.24648170786511914, 'max_leaves': 76}. Best is trial 5 with value: 20.851165521481814.\n",
      "[I 2026-01-18 08:52:29,405] Trial 8 finished with value: 20.865591423028334 and parameters: {'learning_rate': 0.03179692987403197, 'max_depth': 5, 'min_child_weight': 4.333887473524542, 'subsample': 0.7299185561880243, 'colsample_bytree': 0.7299026894968472, 'reg_lambda': 7.27652317231068, 'reg_alpha': 0.003828223434646281, 'gamma': 1.5749719583469393, 'max_leaves': 216}. Best is trial 5 with value: 20.851165521481814.\n",
      "[I 2026-01-18 08:56:10,075] Trial 9 finished with value: 20.85871658160366 and parameters: {'learning_rate': 0.0167812918063357, 'max_depth': 5, 'min_child_weight': 11.994470678865694, 'subsample': 0.7213102298462064, 'colsample_bytree': 0.8467303939911618, 'reg_lambda': 1.4079306525088484, 'reg_alpha': 0.00024322994938220685, 'gamma': 0.6605740840956127, 'max_leaves': 100}. Best is trial 5 with value: 20.851165521481814.\n",
      "[I 2026-01-18 08:57:50,167] Trial 10 finished with value: 21.040636376897638 and parameters: {'learning_rate': 0.09730004867620354, 'max_depth': 3, 'min_child_weight': 2.387999485477284, 'subsample': 0.9424105521012786, 'colsample_bytree': 0.6557834477309457, 'reg_lambda': 14.197406673735852, 'reg_alpha': 0.017070679130645607, 'gamma': 0.12706365461718483, 'max_leaves': 20}. Best is trial 5 with value: 20.851165521481814.\n",
      "[I 2026-01-18 08:58:54,485] Trial 11 finished with value: 20.795285742079983 and parameters: {'learning_rate': 0.051099898123589824, 'max_depth': 6, 'min_child_weight': 18.489380197359093, 'subsample': 0.6594094945568884, 'colsample_bytree': 0.7250544168132262, 'reg_lambda': 5.622678798215666, 'reg_alpha': 1.8752632459933163, 'gamma': 1.1468590256779956, 'max_leaves': 160}. Best is trial 11 with value: 20.795285742079983.\n",
      "[I 2026-01-18 09:00:29,574] Trial 12 finished with value: 20.840698227808957 and parameters: {'learning_rate': 0.04528736946668079, 'max_depth': 6, 'min_child_weight': 22.574776029870996, 'subsample': 0.6612921696987036, 'colsample_bytree': 0.7134083216823794, 'reg_lambda': 10.462866264954625, 'reg_alpha': 0.02371382946702822, 'gamma': 0.5326905459759659, 'max_leaves': 145}. Best is trial 11 with value: 20.795285742079983.\n",
      "[I 2026-01-18 09:01:40,866] Trial 13 finished with value: 20.867270801288164 and parameters: {'learning_rate': 0.04298118032120589, 'max_depth': 6, 'min_child_weight': 20.093372317162203, 'subsample': 0.6599862724860432, 'colsample_bytree': 0.7549993710020413, 'reg_lambda': 3.682434036924375, 'reg_alpha': 0.02279296995952918, 'gamma': 0.9092672036172664, 'max_leaves': 149}. Best is trial 11 with value: 20.795285742079983.\n",
      "[I 2026-01-18 09:01:57,357] Trial 14 finished with value: 20.96879281130403 and parameters: {'learning_rate': 0.11889973249375389, 'max_depth': 6, 'min_child_weight': 7.505418206975876, 'subsample': 0.6526772081788332, 'colsample_bytree': 0.692408043313087, 'reg_lambda': 17.35999765819124, 'reg_alpha': 1.730459356748534, 'gamma': 0.4241401515815676, 'max_leaves': 132}. Best is trial 11 with value: 20.795285742079983.\n",
      "[I 2026-01-18 09:04:11,197] Trial 15 finished with value: 20.752857679555024 and parameters: {'learning_rate': 0.03993109993159447, 'max_depth': 6, 'min_child_weight': 20.42486329056835, 'subsample': 0.6866881721565719, 'colsample_bytree': 0.7752682589935783, 'reg_lambda': 4.377289768306262, 'reg_alpha': 0.04629418953589648, 'gamma': 1.2284550227455073, 'max_leaves': 157}. Best is trial 15 with value: 20.752857679555024.\n",
      "[I 2026-01-18 09:06:31,464] Trial 16 finished with value: 20.873722310402968 and parameters: {'learning_rate': 0.03529700952671534, 'max_depth': 6, 'min_child_weight': 15.136536474647565, 'subsample': 0.7007643105084491, 'colsample_bytree': 0.9462777092989361, 'reg_lambda': 4.110294833599664, 'reg_alpha': 0.06555827657192649, 'gamma': 1.3168558139634945, 'max_leaves': 174}. Best is trial 15 with value: 20.752857679555024.\n",
      "[I 2026-01-18 09:07:28,243] Trial 17 finished with value: 20.887764255918366 and parameters: {'learning_rate': 0.07297109312066834, 'max_depth': 6, 'min_child_weight': 5.349937505942447, 'subsample': 0.6925095393855693, 'colsample_bytree': 0.7734653756444708, 'reg_lambda': 5.948800527156137, 'reg_alpha': 0.004006694051922892, 'gamma': 1.3591875809994571, 'max_leaves': 113}. Best is trial 15 with value: 20.752857679555024.\n",
      "[I 2026-01-18 09:10:16,093] Trial 18 finished with value: 20.881050748273736 and parameters: {'learning_rate': 0.024789514507508735, 'max_depth': 4, 'min_child_weight': 9.195096818132813, 'subsample': 0.7635184231468237, 'colsample_bytree': 0.8154344946207137, 'reg_lambda': 2.4089135038235967, 'reg_alpha': 0.00430076467435109, 'gamma': 1.0461031999248476, 'max_leaves': 163}. Best is trial 15 with value: 20.752857679555024.\n",
      "[I 2026-01-18 09:13:28,222] Trial 19 finished with value: 20.801077701691167 and parameters: {'learning_rate': 0.014460627014899424, 'max_depth': 7, 'min_child_weight': 29.100316243176046, 'subsample': 0.6910059140252981, 'colsample_bytree': 0.7375046099896752, 'reg_lambda': 4.520149779173214, 'reg_alpha': 0.31841661800240734, 'gamma': 1.4676611693987158, 'max_leaves': 113}. Best is trial 15 with value: 20.752857679555024.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_params': {'learning_rate': 0.03993109993159447,\n",
       "  'max_depth': 6,\n",
       "  'min_child_weight': 20.42486329056835,\n",
       "  'subsample': 0.6866881721565719,\n",
       "  'colsample_bytree': 0.7752682589935783,\n",
       "  'reg_lambda': 4.377289768306262,\n",
       "  'reg_alpha': 0.04629418953589648,\n",
       "  'gamma': 1.2284550227455073,\n",
       "  'max_leaves': 157},\n",
       " 'best_val_mae': 20.752857679555024,\n",
       " 'device': 'gpu'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Success Residual innerhalb der Kohorte (Regression)\n",
    "\n",
    "Ziel: Modellierung von **Über- oder Unterperformance** relativ zur Kohorte (Residual statt absoluter Erfolg).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **MAE auf dem Validierungsset minimieren** (robust, gut interpretierbar).\n",
    "\n",
    "Hinweis:\n",
    "- Residual-Targets sind oft verrauscht → Regularisierung ist besonders wichtig.\n",
    "- Kohortenbasierter Zeitsplit verhindert ungewollte Zukunftsinformation.\n"
   ],
   "id": "9665226b3737ea6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T08:16:39.355042Z",
     "start_time": "2026-01-18T08:13:33.547658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_trainer = SuccessResidualTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_res = res_trainer.tune(\n",
    "    ds_res,\n",
    "    n_trials=20,\n",
    "    device=\"cuda\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_res\n",
    "\n"
   ],
   "id": "9c5a8bd785f37cbf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 09:13:33,776] A new study created in memory with name: no-name-8da22665-1c46-4be1-9720-e0c8043b1230\n",
      "[W 2026-01-18 09:16:35,116] Trial 0 failed with parameters: {'learning_rate': 0.11231547254259988, 'max_depth': 3, 'min_child_weight': 16.906547442204772, 'subsample': 0.8431560379361749, 'colsample_bytree': 0.7092691073733662, 'reg_lambda': 2.3096178948333654, 'reg_alpha': 0.004182195933623378, 'gamma': 1.6532306237858043, 'max_leaves': 141} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\GitHub\\data-science\\uni-course\\spotify-data-project\\notebooks\\utils\\tasks\\success_residual.py\", line 123, in objective\n",
      "    model.fit(Xtr, ytr, eval_set=[(Xva, yva)], verbose=False)\n",
      "    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1368, in fit\n",
      "    self._Booster = train(\n",
      "                    ~~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<9 lines>...\n",
      "        callbacks=self.callbacks,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 2434, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self.handle, ctypes.c_int(iteration), dtrain.handle\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-18 09:16:35,243] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m res_trainer = SuccessResidualTrainer(seed=RANDOM_SEED)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m best_res = \u001B[43mres_trainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtune\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds_res\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcuda\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# oder \"cpu\"\u001B[39;49;00m\n\u001B[32m      7\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m best_res\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\uni-course\\spotify-data-project\\notebooks\\utils\\tasks\\success_residual.py:133\u001B[39m, in \u001B[36mSuccessResidualTrainer.tune\u001B[39m\u001B[34m(self, ds, n_trials, device)\u001B[39m\n\u001B[32m    130\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(regression_metrics(yva, pred)[\u001B[33m\"\u001B[39m\u001B[33mMAE\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    132\u001B[39m study = optuna.create_study(direction=\u001B[33m\"\u001B[39m\u001B[33mminimize\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m133\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    136\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mbest_params\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(study.best_params),\n\u001B[32m    137\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mbest_val_mae\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mfloat\u001B[39m(study.best_value),\n\u001B[32m    138\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdevice\u001B[39m\u001B[33m\"\u001B[39m: device,\n\u001B[32m    139\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    388\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34moptimize\u001B[39m(\n\u001B[32m    389\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    390\u001B[39m     func: ObjectiveFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m    397\u001B[39m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    398\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    399\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[32m    400\u001B[39m \n\u001B[32m    401\u001B[39m \u001B[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    488\u001B[39m \u001B[33;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[32m    489\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m490\u001B[39m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     66\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     79\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     80\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs == -\u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    161\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    163\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m164\u001B[39m     frozen_trial_id = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    166\u001B[39m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[32m    167\u001B[39m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[32m    168\u001B[39m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[32m    170\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    255\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mShould not reach.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    257\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    258\u001B[39m     updated_state == TrialState.FAIL\n\u001B[32m    259\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    260\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[32m    261\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m262\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[32m    263\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m trial._trial_id\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    203\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001B[32m    204\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m205\u001B[39m         value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    206\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    207\u001B[39m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    208\u001B[39m         state = TrialState.PRUNED\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\uni-course\\spotify-data-project\\notebooks\\utils\\tasks\\success_residual.py:123\u001B[39m, in \u001B[36mSuccessResidualTrainer.tune.<locals>.objective\u001B[39m\u001B[34m(trial)\u001B[39m\n\u001B[32m     89\u001B[39m params = {\n\u001B[32m     90\u001B[39m     \u001B[38;5;66;03m# Let early stopping choose number of trees\u001B[39;00m\n\u001B[32m     91\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mn_estimators\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m20000\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    110\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmax_leaves\u001B[39m\u001B[33m\"\u001B[39m: trial.suggest_int(\u001B[33m\"\u001B[39m\u001B[33mmax_leaves\u001B[39m\u001B[33m\"\u001B[39m, \u001B[32m16\u001B[39m, \u001B[32m256\u001B[39m),\n\u001B[32m    111\u001B[39m }\n\u001B[32m    113\u001B[39m model = XGBRegressor(\n\u001B[32m    114\u001B[39m     random_state=\u001B[38;5;28mself\u001B[39m.seed,\n\u001B[32m    115\u001B[39m     n_jobs=\u001B[32m4\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    120\u001B[39m     **params,\n\u001B[32m    121\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXtr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mytr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXva\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myva\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(model, \u001B[33m\"\u001B[39m\u001B[33mbest_iteration\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    126\u001B[39m     pred = model.predict(Xva, iteration_range=(\u001B[32m0\u001B[39m, model.best_iteration + \u001B[32m1\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001B[39m, in \u001B[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    772\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig.parameters, args):\n\u001B[32m    773\u001B[39m     kwargs[k] = arg\n\u001B[32m--> \u001B[39m\u001B[32m774\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1368\u001B[39m, in \u001B[36mXGBModel.fit\u001B[39m\u001B[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[39m\n\u001B[32m   1365\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1366\u001B[39m     obj = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1368\u001B[39m \u001B[38;5;28mself\u001B[39m._Booster = \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1369\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1370\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1371\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1372\u001B[39m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[43m=\u001B[49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1373\u001B[39m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1374\u001B[39m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[43m=\u001B[49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1375\u001B[39m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1376\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1377\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1379\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1380\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1382\u001B[39m \u001B[38;5;28mself\u001B[39m._set_evaluation_result(evals_result)\n\u001B[32m   1383\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001B[39m, in \u001B[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    772\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig.parameters, args):\n\u001B[32m    773\u001B[39m     kwargs[k] = arg\n\u001B[32m--> \u001B[39m\u001B[32m774\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\training.py:199\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[39m\n\u001B[32m    197\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001B[32m    198\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m199\u001B[39m \u001B[43mbst\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miteration\u001B[49m\u001B[43m=\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfobj\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    200\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001B[32m    201\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\GitHub\\data-science\\.venv\\Lib\\site-packages\\xgboost\\core.py:2434\u001B[39m, in \u001B[36mBooster.update\u001B[39m\u001B[34m(self, dtrain, iteration, fobj)\u001B[39m\n\u001B[32m   2430\u001B[39m \u001B[38;5;28mself\u001B[39m._assign_dmatrix_features(dtrain)\n\u001B[32m   2432\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2433\u001B[39m     _check_call(\n\u001B[32m-> \u001B[39m\u001B[32m2434\u001B[39m         \u001B[43m_LIB\u001B[49m\u001B[43m.\u001B[49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2435\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[43m.\u001B[49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle\u001B[49m\n\u001B[32m   2436\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2437\u001B[39m     )\n\u001B[32m   2438\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2439\u001B[39m     pred = \u001B[38;5;28mself\u001B[39m.predict(dtrain, output_margin=\u001B[38;5;28;01mTrue\u001B[39;00m, training=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Hit Prediction (Binary Classification)\n",
    "\n",
    "Ziel: Vorhersage, ob ein Track als „Hit“ gilt.\n",
    "\n",
    "Optimierungsziel:\n",
    "- **PR-AUC auf dem Validierungsset maximieren**\n",
    "  (bei unausgeglichenen Klassen oft sinnvoller als ROC-AUC).\n",
    "\n",
    "Zusatz:\n",
    "- Der finale **Threshold** (für F1) wird später auf der Validierung optimiert (wie im Training-Notebook).\n",
    "- GPU ist möglich (XGBoost).\n"
   ],
   "id": "56090ac32e0a91f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hit_trainer = HitTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_hit = hit_trainer.tune(\n",
    "    ds_hit,\n",
    "    n_trials=30,\n",
    "    device=\"cuda\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_hit\n"
   ],
   "id": "e3f2417fa58b5276",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Mood Prediction (Multi-Label)\n",
    "\n",
    "Ziel: Mehrere Mood-Labels pro Track (z.B. happy, sad, chill …).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **Micro-F1 auf dem Validierungsset maximieren**\n",
    "  (gute Standardmetrik bei Multi-Label, weil sie alle Entscheidungen gemeinsam bewertet).\n",
    "\n",
    "Hinweis:\n",
    "- Viele sklearn-Modelle laufen CPU-basiert; GPU ist hier meistens nicht relevant.\n",
    "- Thresholds können später pro Label separat optimiert werden.\n"
   ],
   "id": "bcc19aec79efed2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mood_trainer = MoodTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_mood = mood_trainer.tune(\n",
    "    ds_mood,\n",
    "    n_trials=30,\n",
    ")\n",
    "\n",
    "best_mood\n"
   ],
   "id": "89547a8ae21dd7fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Ranker (Learning-to-Rank)\n",
    "\n",
    "Ziel: Tracks innerhalb einer Kohorte sinnvoll zu ranken (Top-K Qualität).\n",
    "\n",
    "Optimierungsziel:\n",
    "- **Mean NDCG@10 auf dem Validierungsset maximieren**.\n",
    "\n",
    "Wichtig:\n",
    "- Ranking benötigt eine saubere Gruppierung (z.B. pro `cohort_ym`).\n",
    "- GPU ist möglich (XGBRanker).\n"
   ],
   "id": "b8a79c410503407a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rank_trainer = RankerTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_rank = rank_trainer.tune(\n",
    "    ds_pct,        # typischerweise nutzt der Ranker das gleiche X, aber anderes Training/Grouping\n",
    "    n_trials=30,\n",
    "    device=\"cuda\", # oder \"cpu\"\n",
    "    k=10\n",
    ")\n",
    "\n",
    "best_rank\n"
   ],
   "id": "2537c64a6333344",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuning: Artist Trajectory (Growth & Breakout)\n",
    "\n",
    "Ziel: Künstlerentwicklung über Zeit modellieren.\n",
    "\n",
    "Teilaufgaben:\n",
    "- **Growth (Regression):** log1p-transformiertes Wachstum → **MAE minimieren**\n",
    "- **Breakout (Binary):** Breakout-Event → **PR-AUC maximieren**\n",
    "\n",
    "Hinweis:\n",
    "- Zeitliche Sortierung ist Pflicht, damit der Split korrekt ist.\n",
    "- GPU ist möglich (XGBoost).\n"
   ],
   "id": "26f997d24f2a85a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "artist_trainer = ArtistTrajectoryTrainer(seed=RANDOM_SEED)\n",
    "\n",
    "best_artist = artist_trainer.tune(\n",
    "    data.artist_panel,\n",
    "    n_trials=30,\n",
    "    device=\"cuda\",   # oder \"cpu\"\n",
    ")\n",
    "\n",
    "best_artist\n"
   ],
   "id": "2fdee917428c672f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Unsupervised Tuning: Artist Clustering (KMeans)\n",
    "\n",
    "In diesem Schritt optimieren wir das Clustering **ohne Ground Truth**.\n",
    "Dafür testen wir verschiedene Parameter (z.B. `k` und PCA-Dimensionen) auf einem **Sample**, um die Laufzeit gering zu halten.\n",
    "\n",
    "**Bewertung (Heuristiken):**\n",
    "- **Silhouette Score** (höher = besser getrennte Cluster)\n",
    "- **Davies–Bouldin Index** (niedriger = kompakter / besser)\n",
    "\n",
    "Anschließend trainieren wir das beste Setup auf dem vollständigen Datensatz und erzeugen optional eine 2D-PCA-Visualisierung.\n"
   ],
   "id": "cfb7277b1f5dd787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RNG = np.random.RandomState(RANDOM_SEED)\n",
    "\n",
    "# Sample Artists für schnellere Evaluierung\n",
    "sample_n = 8000\n",
    "idx = RNG.choice(len(data.artist_df), size=sample_n, replace=False)\n",
    "artist_sample = data.artist_df.iloc[idx].copy()\n",
    "\n",
    "def eval_clustering(k, pca_dim=16, scale=True):\n",
    "    runner = ArtistClusteringRunner(k=k, seed=RANDOM_SEED, scale=scale, pca_dim=pca_dim)\n",
    "    models, artifact, extra = runner.run(artist_sample)\n",
    "\n",
    "    X_used = extra[\"X_used\"]\n",
    "    labels = extra[\"labels\"]\n",
    "\n",
    "    sil = silhouette_score(X_used, labels)\n",
    "    db = davies_bouldin_score(X_used, labels)\n",
    "\n",
    "    return {\n",
    "        \"k\": k,\n",
    "        \"pca_dim\": pca_dim,\n",
    "        \"scale\": scale,\n",
    "        \"silhouette\": float(sil),\n",
    "        \"davies_bouldin\": float(db),\n",
    "        \"artifact\": artifact,\n",
    "    }\n",
    "\n",
    "candidates = []\n",
    "for k in [10, 15, 20, 25, 30, 35, 40, 50]:\n",
    "    for pca_dim in [8, 12, 16]:\n",
    "        candidates.append(eval_clustering(k=k, pca_dim=pca_dim, scale=True))\n",
    "\n",
    "df_c = pd.DataFrame([{k: v for k, v in c.items() if k != \"artifact\"} for c in candidates])\n",
    "df_c.sort_values([\"silhouette\", \"davies_bouldin\"], ascending=[False, True]).head(10)\n"
   ],
   "id": "3f51f1117b08dac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_row = df_c.sort_values([\"silhouette\", \"davies_bouldin\"], ascending=[False, True]).iloc[0]\n",
    "best_cluster_cfg = best_row.to_dict()\n",
    "best_cluster_cfg\n"
   ],
   "id": "8e339745ff7836c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_runner = ArtistClusteringRunner(\n",
    "    k=int(best_cluster_cfg[\"k\"]),\n",
    "    seed=RANDOM_SEED,\n",
    "    scale=bool(best_cluster_cfg[\"scale\"]),\n",
    "    pca_dim=int(best_cluster_cfg[\"pca_dim\"]),\n",
    ")\n",
    "cluster_models, cluster_artifact, cluster_extra = cluster_runner.run(data.artist_df)\n",
    "\n",
    "# optional plot on sample\n",
    "cluster_runner.plot_pca2(cluster_extra[\"X_used\"], cluster_extra[\"labels\"])\n"
   ],
   "id": "8d873da90b286227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Embeddings & Track Similarity: Plausibilitäts-Checks\n",
    "\n",
    "Track-Similarity ist in der Praxis oft **qualitativ** zu bewerten (klingen/fühlen sich die Nachbarn ähnlich an?).\n",
    "Hier führen wir daher einen stabilen Check durch:\n",
    "\n",
    "- Embedding einmal fitten\n",
    "- Mehrere **gültige Track-Keys** auswählen\n",
    "- Für jeden Key die Top-K ähnlichsten Tracks abrufen\n",
    "\n",
    "Ziel: Sicherstellen, dass die Pipeline funktioniert, die Keys korrekt gematcht werden und die Ergebnisse plausibel sind.\n"
   ],
   "id": "c3fb147c875a2603"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sim_runner = TrackSimilarityRunner()\n",
    "sim_models, sim_artifact = sim_runner.fit(data.track_df)\n",
    "\n",
    "track_keys = data.track_df.index.to_numpy()\n",
    "RNG = np.random.RandomState(RANDOM_SEED)\n",
    "example_keys = RNG.choice(track_keys, size=5, replace=False)\n",
    "\n",
    "# column that contains the title\n",
    "title_col = \"name\"   # adjust if needed\n",
    "\n",
    "def add_titles(similar_list):\n",
    "    \"\"\"similar_list: [(track_key, score), ...] -> [(track_key, title, score), ...]\"\"\"\n",
    "    out = []\n",
    "    for k, score in similar_list:\n",
    "        # pull title by index\n",
    "        try:\n",
    "            t = data.track_df.loc[k, title_col]\n",
    "        except Exception:\n",
    "            t = None\n",
    "        out.append((k, t, float(score)))\n",
    "    return out\n",
    "\n",
    "examples_with_titles = {}\n",
    "\n",
    "for key in example_keys:\n",
    "    sims = sim_runner.get_similar(\n",
    "        track_key=key,\n",
    "        track_index=data.track_df.index,\n",
    "        embeddings=sim_models[\"embeddings\"],\n",
    "        top_k=3\n",
    "\n",
    "    )\n",
    "\n",
    "    # also include the query track title\n",
    "    query_title = data.track_df.loc[key, title_col] if title_col in data.track_df.columns else None\n",
    "\n",
    "    examples_with_titles[str(key)] = {\n",
    "        \"query\": {\"track_key\": key, \"title\": query_title},\n",
    "        \"similar\": add_titles(sims)\n",
    "    }\n",
    "\n",
    "examples_with_titles"
   ],
   "id": "a29b6287716cf5ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Finalisierung: Best-Modelle retrainen & Artefakte speichern\n",
    "\n",
    "Jetzt retrainen wir jedes Modell mit den **besten gefundenen Hyperparametern** und speichern:\n",
    "\n",
    "- Modelle nach `PATHS.tuned_models_dir`\n",
    "- Tuning-Report (Scores + Parameter + Artefakte) nach `PATHS.reports_dir_tuned`\n",
    "\n",
    "Damit ist die Tuning-Runde reproduzierbar und die Ergebnisse sind sauber versioniert.\n"
   ],
   "id": "72274e452a264dec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tuned_report = {}\n",
    "# success_pct\n",
    "pct_model, pct_metrics = pct_trainer.fit_eval(ds_pct,best_pct[\"best_params\"])\n",
    "save_joblib({\"model\": pct_model, \"best_params\": best_pct}, PATHS.tuned_models_dir / \"success_pct_tuned.joblib\")\n",
    "tuned_report[\"success_pct\"] = {\"best\": best_pct, \"metrics\": pct_metrics}\n",
    "\n",
    "# success_residual\n",
    "res_model, res_metrics = res_trainer.fit_eval(ds_res,best_res[\"best_params\"])\n",
    "save_joblib({\"model\": res_model, \"best_params\": best_res}, PATHS.tuned_models_dir / \"success_residual_tuned.joblib\")\n",
    "tuned_report[\"success_residual\"] = {\"best\": best_res, \"metrics\": res_metrics}\n",
    "\n",
    "# hit\n",
    "hit_model, hit_metrics, hit_thr = hit_trainer.fit_eval(ds_hit, params=best_hit[\"best_params\"])\n",
    "save_joblib({\"model\": hit_model, \"threshold\": hit_thr, \"best_params\": best_hit}, PATHS.tuned_models_dir / \"hit_tuned.joblib\")\n",
    "tuned_report[\"hit\"] = {\"best\": best_hit, \"metrics\": hit_metrics}\n",
    "\n",
    "# mood (optional)\n",
    "if best_mood is not None:\n",
    "    mood_model, mood_metrics, mood_thresholds = mood_trainer.fit_eval(ds_mood, params=best_mood[\"best_params\"])\n",
    "    save_joblib({\"model\": mood_model, \"thresholds\": mood_thresholds, \"best_params\": best_mood}, PATHS.tuned_models_dir / \"mood_tuned.joblib\")\n",
    "    tuned_report[\"mood\"] = {\"best\": best_mood, \"metrics\": mood_metrics}\n",
    "\n",
    "# ranker (optional)\n",
    "if \"best_rank\" in globals() and best_rank is not None:\n",
    "    rank_model, rank_metrics = rank_trainer.fit_eval(ds_pct, params=best_rank[\"best_params\"])\n",
    "    save_joblib({\"model\": rank_model, \"best_params\": best_rank}, PATHS.tuned_models_dir / \"ranker_tuned.joblib\")\n",
    "    tuned_report[\"ranker\"] = {\"best\": best_rank, \"metrics\": rank_metrics}\n",
    "\n",
    "# artist clustering (save fitted full model)\n",
    "save_joblib({\"models\": cluster_models, \"artifact\": cluster_artifact, \"best_cfg\": best_cluster_cfg},\n",
    "            PATHS.tuned_models_dir / \"artist_clustering_tuned.joblib\")\n",
    "tuned_report[\"artist_clustering\"] = {\"best_cfg\": best_cluster_cfg, \"artifact\": cluster_artifact}\n",
    "\n",
    "# track similarity (save embedding)\n",
    "save_joblib({\"models\": sim_models, \"artifact\": sim_artifact}, PATHS.tuned_models_dir / \"track_similarity.joblib\")\n",
    "tuned_report[\"track_similarity\"] = sim_artifact\n",
    "\n",
    "# final tuned report json\n",
    "tuned_report[\"run_config\"] = {\"seed\": RANDOM_SEED, \"allow_leaky_features\": ALLOW_LEAKY_FEATURES}\n",
    "save_json(tuned_report, PATHS.reports_dir_tuned / \"tuned_metrics_report.json\")\n",
    "\n",
    "tuned_report.keys()\n"
   ],
   "id": "c07598055e555079",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
