{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "This notebook implements and compares common anomaly detection approaches:\n",
    "\n",
    "1. Gaussian Anomaly Detection (multivariate)\n",
    "2. Isolation Forest\n",
    "3. One-Class SVM\n",
    "4. Local Outlier Factor (LOF)\n",
    "5. Robust Covariance (EllipticEnvelope)\n",
    "6. PCA Reconstruction Error\n",
    "7. Autoencoder (Keras/TensorFlow)\n"
   ],
   "id": "8f8440c8384e649c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Imports & Helpers",
   "id": "e723a0acc4441c01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T16:18:37.671884Z",
     "start_time": "2025-12-30T16:18:31.568633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(42)\n"
   ],
   "id": "7025f6defcf6035e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Utility Functions",
   "id": "74b60be20ac9e727"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T16:21:01.702187Z",
     "start_time": "2025-12-30T16:21:01.687161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_history(y_true,y_pred,title=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate predictions (0=normal, 1=anomaly).\n",
    "    \"\"\"\n",
    "\n",
    "    precision,recall,f1,_ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average='binary',\n",
    "        zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1:        {f1:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"normal\", \"anomaly\"], zero_division=0))\n",
    "\n",
    "def plot_2d_results(X, y_true, y_pred, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plot 2D scatter with true labels and predicted anomalies.\n",
    "    Assumes X has 2 columns.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7, 6))\n",
    "\n",
    "    # Plot normals (true)\n",
    "    normal_idx = (y_true == 0)\n",
    "    plt.scatter(X[normal_idx, 0], X[normal_idx, 1], s=18, alpha=0.6, label=\"True Normal\")\n",
    "\n",
    "    # Plot true anomalies\n",
    "    anomaly_idx = (y_true == 1)\n",
    "    plt.scatter(X[anomaly_idx, 0], X[anomaly_idx, 1], s=30, alpha=0.8, label=\"True Anomaly\")\n",
    "\n",
    "    # Overlay predicted anomalies with 'x'\n",
    "    pred_anomaly_idx = (y_pred == 1)\n",
    "    plt.scatter(X[pred_anomaly_idx, 0], X[pred_anomaly_idx, 1], s=80, marker=\"x\", label=\"Predicted Anomaly\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()\n",
    "\n",
    "def pick_threshold_from_scores(scores, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Convert anomaly scores into a threshold using a contamination ratio.\n",
    "    Higher score => more anomalous (assumed).\n",
    "\n",
    "    We select threshold such that top contamination fraction becomes anomalies.\n",
    "    \"\"\"\n",
    "    thresh = np.quantile(scores, 1 - contamination)\n",
    "    return thresh\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "3ccf1d03fb2774e9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Dataset Creation",
   "id": "cba2052261888f2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T16:22:00.107557Z",
     "start_time": "2025-12-30T16:22:00.045350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a 2D dataset: normal clusters + injected anomalies\n",
    "n_normal = 2000\n",
    "n_anom = 100\n",
    "\n",
    "# Two Gaussian blobs as normal behavior\n",
    "mean1, cov1 = [0, 0], [[1.0, 0.3], [0.3, 1.2]]\n",
    "mean2, cov2 = [5, 5], [[1.2, -0.2], [-0.2, 1.0]]\n",
    "\n",
    "X1 = np.random.multivariate_normal(mean1, cov1, n_normal // 2)\n",
    "X2 = np.random.multivariate_normal(mean2, cov2, n_normal // 2)\n",
    "X_normal = np.vstack([X1, X2])\n",
    "\n",
    "# Anomalies far away / scattered\n",
    "X_anom = np.random.uniform(low=-8, high=12, size=(n_anom, 2))\n",
    "\n",
    "X = np.vstack([X_normal, X_anom])\n",
    "\n",
    "# Labels: 0=normal, 1=anomaly\n",
    "y = np.hstack([np.zeros(len(X_normal)), np.ones(len(X_anom))]).astype(int)\n",
    "\n",
    "# Shuffle\n",
    "idx = np.random.permutation(len(X))\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Anomaly rate:\", y.mean())\n"
   ],
   "id": "86325061ae804e7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2100, 2)\n",
      "Anomaly rate: 0.047619047619047616\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train/Test Split + Scaling",
   "id": "5f49391e38d75ca2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T16:23:23.837971Z",
     "start_time": "2025-12-30T16:23:23.823285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(\n",
    "    X,y,test_size=0.35,random_state=42,stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train anomaly rate:\", y_train.mean())\n",
    "print(\"Test anomaly rate: \", y_test.mean())"
   ],
   "id": "1652246bbc72878d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train anomaly rate: 0.047619047619047616\n",
      "Test anomaly rate:  0.047619047619047616\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
